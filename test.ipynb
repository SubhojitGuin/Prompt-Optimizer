{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, GoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 0, 'page_label': '1'}, page_content='INFORMATICS INSTITUTE OF TECHNOLOGY \\nIn Collaboration with \\nUNIVERSITY OF WESTMINSTER \\n \\nHybrid Prompt Compression for RAG Pipelines \\n \\nA Project Proposal by \\nChenula Senkith Jayasinghe \\n \\nSupervised by \\nMr Vinula Uthsara Buthgamumudalige \\n \\n \\n \\n \\n \\n \\n02/2025'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 1, 'page_label': '2'}, page_content='Abstract  \\n \\nWith the huge growth of unstructured textual data in the healthcare domain, retrieval and \\nsummarization of relevant information is a critical problem for healthcare professionals and \\nresearchers. We propose a Retrieval -Augmented Generation (RAG) pipeline f or prompt \\ncompression to minimize tokens while achieving a high response accuracy. It combines dense \\nvector-based retrieval using FAISS with two stage compression: an extractive stage to identify the \\nkeys sentences and an abstractive stage to compress the extracted information. \\nThe user’s query is combined with the compressed content for the large language models (LLMs) \\nsuch as GPT -3 or ChatGPT, creating an optimized prompt for an effective and cost -efficient \\nresponse. For query encoding, the project utilizes Sentence-BERT, for abstractive compression it \\nuses BART, and for user interaction it utilizes Streamlit interface. Finally, the system is evaluated \\nusing metrics including compression ratio and token savings, ROUGE scores and response \\naccuracy. This project seeks to provide a practical and scalable solution to the problem of querying \\nlarge medical datasets with low token consumption in LLM based applications.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 2, 'page_label': '3'}, page_content='Table of Contents \\n  \\nTable of Contents ................................ ................................ ................................ ............. 3 \\nList of Tables ................................ ................................ ................................ ................... 5 \\nList of Figures ................................ ................................ ................................ .................. 6 \\nChapter 1: Introduction ................................ ................................ ................................ ....... 7 \\n1.1 Chapter Overview ................................ ................................ ................................ ....... 7 \\n1.2 Problem Identification ................................ ................................ ................................  7 \\n1.3 Problem Background / Problem Domain ................................ ................................ ...... 8 \\n1.4 Problem Definition ................................ ................................ ................................ .....10 \\n1.5 Research Gap ................................ ................................ ................................ ............11 \\n1.6 Contribution to the Body of Knowledge ................................ ................................ ......14 \\n1.7 Research Aim ................................ ................................ ................................ ............17 \\n1.8 Research Objectives ................................ ................................ ................................ ...17 \\n1.9 Novelty ................................ ................................ ................................ ......................19 \\n1.10 Chapter Summary................................ ................................ ................................ ....21 \\nChapter 2: Requirements Specification ................................ ................................ ................22 \\n2.1 Chapter Overview ................................ ................................ ................................ ......22 \\n2.2 Rich Picture Diagram ................................ ................................ ................................ 22 \\n2.3 Stakeholder Analysis ................................ ................................ ................................ ..23 \\n2.4 Requirement Elicitation Methodologies ................................ ................................ ......23 \\n2.5 Findings from Elicitation ................................ ................................ ............................24 \\n2.6 Context Diagram ................................ ................................ ................................ .......27 \\n2.7 Use Case Diagram and Descriptions................................ ................................ ............27 \\n2.8 Functional and Non-Functional Requirements ................................ ............................28 \\n2.9 Chapter Summary ................................ ................................ ................................ .....30 \\nChapter 3: Design ................................ ................................ ................................ ...............31 \\n3.1 Chapter Overview ................................ ................................ ................................ ......31 \\n3.3 System Architecture Design ................................ ................................ ........................32 \\n3.4 Detailed Design ................................ ................................ ................................ ..........35 \\n3.5 Algorithm Design ................................ ................................ ................................ .......35 \\n3.6 UI Design Wireframe ................................ ................................ ................................ .37 \\n3.7 Chapter Summary ................................ ................................ ................................ .....38'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 3, 'page_label': '4'}, page_content='Chapter 4: Implementation ................................ ................................ ................................ .39 \\n4.1 Chapter Overview ................................ ................................ ................................ ......39 \\n4.2 Technology Selection ................................ ................................ ................................ ..39 \\n4.3 Core Functionalities Implementation ................................ ................................ ..........43 \\n4.4 User Interface Implementation ................................ ................................ ...................46 \\n4.5 Challenges and Solutions ................................ ................................ ............................50 \\n4.6 Chapter Summary ................................ ................................ ................................ .....51 \\nChapter 5: Testing ................................ ................................ ................................ ..............52 \\n5.1 Chapter Overview ................................ ................................ ................................ ......52 \\n5.2 Testing Criteria ................................ ................................ ................................ .........52 \\n5.3 Functional Testing ................................ ................................ ................................ .....55 \\n5.4 Non-Functional Testing ................................ ................................ .............................. 57 \\n5.5 Model Testing (for ML Projects) ................................ ................................ ................59 \\n5.6 Edge Case Testing ................................ ................................ ................................ ......60 \\n5.7 Limitations of Testing Process ................................ ................................ ....................60 \\n5.9 Chapter Summary ................................ ................................ ................................ .....61 \\nChapter 6: Interim Conclusion ................................ ................................ ............................62 \\n6.1 Chapter Overview ................................ ................................ ................................ ......62 \\n6.2 Achievements of Aims & Objectives................................ ................................ ............62 \\n6.3 Challenges and Lessons Learned ................................ ................................ ................62 \\n6.4 Remaining Work ................................ ................................ ................................ .......64 \\n6.5 Chapter Summary ................................ ................................ ................................ .....65'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 4, 'page_label': '5'}, page_content='List of Tables \\n \\nTable 1 Summary of Research Gap ................................ ................................ ..........................14 \\nTable 2 Research Objectives ................................ ................................ ................................ ....19 \\nTable 3 Requirement Elicitation Methodologies ................................ ................................ .........24 \\nTable 4 Litreature Review ................................ ................................ ................................ .........25 \\nTable 5 Interviews ................................ ................................ ................................ .....................26 \\nTable 6 Functional Requirements................................ ................................ .............................. 29 \\nTable 7 Non - Functional Requirements ................................ ................................ ....................30 \\nTable 8 Design Goals................................ ................................ ................................ ................32 \\nTable 9 Technology Stack ................................ ................................ ................................ .........40 \\nTable 10 Dataset Selection ................................ ................................ ................................ .......41 \\nTable 11 Programming Languages ................................ ................................ ...........................42 \\nTable 12 Library Toolkit ................................ ................................ ................................ .............43 \\nTable 13 Core Functionality Implementation ................................ ................................ .............44 \\nTable 14 UI Elements................................ ................................ ................................ ................47 \\nTable 15 Challengers and Solutions ................................ ................................ ..........................51 \\nTable 16 Non-Functional Requirements ................................ ................................ ....................53 \\nTable 17 Model Performance Metrics ................................ ................................ ........................54 \\nTable 18 Functional Testing ................................ ................................ ................................ ......57 \\nTable 19 Usability Testing ................................ ................................ ................................ .........58 \\nTable 20 Dataset Testing ................................ ................................ ................................ ..........59'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 5, 'page_label': '6'}, page_content='List of Figures \\n \\nFigure 1 Rich Picture Diagram ................................ ................................ ................................ ..23 \\nFigure 2 Context Diagram ................................ ................................ ................................ .........27 \\nFigure 3 Architecture Diagram ................................ ................................ ................................ ..33 \\nFigure 4 Query Embedding ................................ ................................ ................................ .......36 \\nFigure 5 Hybrid Compression ................................ ................................ ................................ ....36 \\nFigure 6 Prompt Generation ................................ ................................ ................................ ......37 \\nFigure 7 UI Wireframe ................................ ................................ ................................ ...............37 \\nFigure 8 User Interface ................................ ................................ ................................ .............49'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 6, 'page_label': '7'}, page_content='Chapter 1: Introduction \\n1.1 Chapter Overview \\nThe purpose of this chapter is to give an initial view of the problem domain and the need of \\nresolving the main challenges in retrieving and compressing unstructured medical data. It lays the \\nfoundation for the research objectives, methodology and the enti re project structure. This chapter \\njustifies that existing systems have limitations, and thus a Retrieval-Augmented Generation (RAG) \\npipeline that combines dense retrieval and prompt compression is needed to solve the problem \\nidentified. \\nThe chapter connects the problem domain to the following chapters by explaining the issues of \\nworking with large amounts of unstructured data in healthcare domain and making input suitable \\nfor big language models (LLMs). Current methods either generate sem antically meaningful \\nretrieval or generate summaries that are too long to be efficiently processed by LLMs. Thus, the \\nroot causes and gaps in current systems need to be understood to help develop a good solution. \\nAdditionally, this chapter also introduces the research gap and the proposed approach by providing \\na combination of dense retrieval using FAISS and extractive abstractive compression to address \\nthe limitations of traditional retrieval and summarization met hods. This chapter lays out the \\nobjectives and contributions of the project by setting the scene for the system design, \\nimplementation, and evaluation of the remaining chapters. \\n \\n \\n1.2 Problem Identification \\nThis section is to define the real world problem this project wants to solve, both in technical and \\npractical terms. It focuses on the importance of the problem within the domain of healthcare \\ninformatics, more specifically, the efficient retrieval and com pression of large scale drug review \\ndata for large language models (LLMs). \\nThere are large collections of user generated content (reviews, feedback and experiences) for \\nvarious medications in health care platforms like WebMD and UCI ML Drug Reviews. In these \\nreviews, drug effectiveness, side effects, dosage experiences are descri bed with the help of \\ndifferent patients and healthcare professionals. Although this data has good information, it is \\nunstructured, repetitive and redundant, so it is difficult to retrieve and summarize relevant \\ninformation quickly.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 7, 'page_label': '8'}, page_content='The problem is, as follows: \\n1. Large Volume of Data: \\nThe reviews are usually in thousands, and a user cannot process them manually. \\n2. Scattered and Redundant Information: \\nScattered across multiple reviews and merged with repetitions, important details such as side \\neffects, dosage recommendations and treatment outcomes are mixed. But to search for concise and \\naccurate information is difficult. \\n3. Complexity of Summarization: \\nThere are challenges in generating summaries from long texts from user generated content, which \\nvary in writing styles, formats and may contain irrelevant information. \\n4. LLM Token Constraints: \\nWhen interfacing with LLMs like GPT3 or ChatGPT, you have to deal with tokens limitations \\nsince such models have a fixed number of tokens per request (e.g., GPT3 has a maximum of 4,096 \\ntokens per request). For example, if a query produces too many uncompre ssed chunks, the LLM \\nmay produce half or incomplete answers. \\n \\n \\n1.3 Problem Background / Problem Domain \\nDigital data production in the healthcare industry has experienced a rapid growth due to \\ninnovations in online health platforms, electronic health records (EHRs), and patient generated \\ncontent. WebMD, Drugs.com, and UCI ML Drug Reviews are platforms with user feedback about \\nmedications such as reports of side effects, dosage effectiveness and patient experiences. \\nNevertheless, the data in this study is unstructured and textual in nature, which makes efficient \\nretrieval and processing difficult.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 8, 'page_label': '9'}, page_content='Trends Shaping the Problem Domain \\n1. Growth of User-Generated Content: \\nAs medical advice and patient reviews are increasingly sought out online, there are huge \\nunstructured datasets being amassed. Because patients often have subjective and diverse \\nexperiences with medications, they have variability in how they write, what they write, and \\nin the structure of the reviews. \\nConstraints: Drug effectiveness and side effect expressions are diverse and should be \\nunderstood by a retrieval system. \\n2. Adoption of Large Language Models (LLMs): \\nApplications of such advances in Natural Language Processing (NLP), including GPT -3, \\nBERT and ChatGPT, include automated response generation, clinical decision support and \\npersonalized recommendations. Nonetheless, these models are limited by token limits and \\nefficient input prompt construction is essential for real world use. \\nOptimization: In order to interact with LLMs cost effectively, we need to optimize token \\nusage via prompt compression. \\n3. Emphasis on Evidence-Based Medicine: \\nThere is an increasing focus on data-driven, evidence-based decision-making in healthcare. \\nMedical professionals rely on aggregated insights from multiple patient experiences and \\nclinical outcomes to make informed decisions. However, the manual aggregation  of \\nscattered and redundant information from large datasets is time -consuming and prone to \\nhuman error. \\nImplication: Automated systems for retrieving and summarizing key information are \\nessential to support evidence-based decision-making. \\n4. LLM-Compatible Prompt Construction \\nThe final compressed prompt must contain sufficient context and information to allow the \\nLLM to generate relevant, accurate, and factually correct responses to the user query. \\nPoorly structured or excessively compressed prompts may lead to hallucinations o r \\ninaccurate outputs from the LLM. The challenge is to optimize token savings without \\nsacrificing the completeness and correctness of the generated response.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 9, 'page_label': '10'}, page_content='1.4 Problem Definition \\nProblem Statement \\n“ How can we efficiently retrieve and compress large-scale, unstructured drug review data to \\nconstruct token-optimized prompts for large language models (LLMs) while maintaining \\naccuracy, contextual relevance, and minimal token usage? ” \\nTechnical and Operational Aspects of the Problem \\n1. Efficient Information Retrieval \\nMany large medical datasets like WebMD Drug Reviews contain thousands of user \\ngenerated reviews for drugs with descriptions of how effective it is, what side effects it \\ncreates, and patient experience. The problem is how we can retrieve only the most relevant \\nknowledge chunks which correspond to a user query while retrieving the knowledge \\nchunks in a way that the knowledge retrieval system understands semantic meaning, not a \\nsimple keyword match. \\nOperational Challenge: Traditional retrieval systems based on keyword search methods \\nare not good at understanding complex natural language queries and frequently produce \\nirrelevant or incomplete results. Thus, it needs a dense vector based retrieval system (using \\nFAISS) to achieve high retrieval accuracy. \\n2. Compression of Retrieved Information \\nAfter that, they have to compress the relevant reviews into a small token footprint to pass \\nas a prompt to large language models. Since LLMs like GPT-3 have strict token limitations \\n(i.e., 4,096 tokens per request for GPT -3), they cannot process long, unco mpressed \\ndocuments directly. The prompt construction may exclude or truncate critical details \\nwithout compression. \\nTechnical Challenge : The compression must be able to strike a balance between \\ndecreasing token count and maintaining important information. Truncation or extractive \\nsummarization may not capture nuances and context. Thus, a two stage compression \\nmethod is required. \\nStage 1 (Extractive Compression): Extractive compression, that is, identify key sentences \\ndirectly from the retrieved reviews.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 10, 'page_label': '11'}, page_content='Stage 2  (Abstractive Compression): Compress and rephrase the extracted sentences to \\nmake them coherent, and to be token efficient. \\n3. LLM-Compatible Prompt Construction \\nThe compressed prompt has to have enough context and information for LLM to generate \\nrelevant, accurate, and factually correct response to the user query. If prompts are badly \\nstructured or too compact, then this can cause hallucinations or incorrect outpu ts by the \\nLLM. The difficulty is to achieve token savings optimality while keeping the generated \\nresponse as complete and correct as possible. \\n \\n \\n1.5 Research Gap \\n \\n1.5.1 Overview of Existing Solutions \\nThere are numerous studies and systems which focused on information retrieval, summarization, \\nand processing very large text datasets using large language models (LLMs). Traditional \\napproaches include: \\n1. Information Retrieval Systems: \\nThe commonly used ways of retrieving relevant documents based on user queries are by \\nkeyword based search engines and by TF-IDF based retrieval systems. \\nFor dense vector based retrieval systems, like those using BERT embeddings or FAISS, \\nretrieving using semantic meaning has been shown to improve performance over exact \\nkeyword matches. \\n2. Summarization Techniques: \\nExtractive summarization: Selects the most important sentences from the text verbatim. \\nBoth models such as BERTSUM and Sumy fall in this category. \\nAbstractive Summarization: Generating concise, human -like summaries that rephrase the \\nkey information are referred to as abstractive summarization. BART and PEGASUS are \\npopular abstractive models. \\n3. Prompt Construction for LLMs: \\nThe current system finds user queries and give them to LLMs, or reduce the token count \\nof the input by means of generic summarization.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 11, 'page_label': '12'}, page_content='1.5.2 Deficiencies in Existing Systems and Knowledge \\nDespite advancements in retrieval, summarization, and LLM -based applications, several \\nunresolved issues remain: \\n1. Inefficient Retrieval Mechanisms: \\nRetrieval systems based on keywords fail to provide semantic meaning of user query. For \\nexample: “What are the side effects of ibuprofen?” If they don’t explicitly match the query \\nterms, may not retrieve documents that mention related terms such as “dizzin ess”, or \\n“nausea”. \\nDespite the density of the retrieval systems utilized, existing methods tend to design their \\nretrieval towards query -document full document retrieval rather than relevant document \\nchunks within that document, resulting in large and redundant retrieved outputs. \\n2. Lack of Token Optimization in Summarization: \\nTypically, summarization systems aim to produce human readable summaries and optimize \\nfor efficiency of tokens when interacting with models such as GPT -3 or ChatGPT, which \\nare limited in terms of the number of tokens they can work with. \\nExtractive only systems choose redundant and verbose sentences and Abstractive only \\nsystems can lose very important details because of oversimplification. A key gap is that \\ncurrent systems do not have a hybrid (extractive + abstractive) approach. \\n3. Balancing Compression and Accuracy: \\nIn the case of complex, multi -faceted information like drug side effects and dosage \\nrecommendations, the loss of critical detail can occur even with excessive compression. \\nIn contrast, minimal compression causes token overload and hence yields incomplete or \\ntruncated responses from LLMs. There are not effective strategies in current literature to \\nbalance compression ratio and output accuracy. \\n4. Limited Integration with LLMs for Real-Time Use: \\nSimilar to LLMs, LLMs have already been successfully used for general purpose question \\nanswer and text generation but existing systems still do not provide real time integration \\nwhere user queries are taken in automatically, compressed and structured into prompts for \\nimmediate processing by LLMs. \\nAlso, user end interfaces (e.g., healthcare professionals) are not well explored.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 12, 'page_label': '13'}, page_content='1.5.3 Why Addressing This Gap Is Necessary \\n1. Practical Need for Efficient Information Retrieval in Healthcare: \\nTimely access to accurate and concise drug related information can help in making \\ndecisions both for medical professionals as well as patients in the healthcare domain. \\nHowever, current systems are inefficient and prone to errors as users need to manually go \\nthrough several reviews. \\nTo address this gap, we develop a dense retrieval and prompt compression pipeline that \\nenables users to get to actionable knowledge in real time. \\n2. Cost-Effectiveness in Using LLMs: \\nGPT-3 is a large language model and it has token based pricing model. In the absence of \\nthe proper token optimization, queries may pay high costs or get truncated results from the \\ntoken limit. \\nThe project closes that gap by compressing prompts without losing key info so the costs \\nare reduced and the LLM capabilities are used effectively. \\n3. Scalable and Flexible Solutions: \\nWith the increase in volume of user generated medical content, the system must be scalable \\nfor large datasets with minimal performance loss. \\nThis project is scalable and generalizable to other domains such as legal documents, \\nfinancial reports, scientific papers by integrating dense retrieval and hybrid compression. \\n \\n1.5.4 Summary of the Research Gap \\n \\nAspect Existing Limitation Proposed Solution \\nRetrieval Efficiency Keyword-based and \\ndocument-level retrieval fail \\nto return contextually relevant \\nchunks \\nUse dense vector-based \\nretrieval via FAISS and \\nBERT \\nToken Optimization Existing summarization \\nfocuses on human readability, \\nnot token savings \\nImplement a two-stage \\ncompression pipeline \\n(extractive + abstractive) \\nCompression-Accuracy Excessive compression leads Optimize compression by'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 13, 'page_label': '14'}, page_content='Tradeoff to loss of details, minimal \\ncompression leads to token \\noverload \\nbalancing token savings and \\noutput accuracy \\nReal-Time User Interaction Limited integration with \\ninteractive LLM-based \\nsystems \\nDevelop a real-time User \\ninterface for query \\nprocessing \\nTable 1 Summary of Research Gap \\n \\n1.6 Contribution to the Body of Knowledge \\n1.6.1 Theoretical Contributions \\n1. Integration of Prompt Compression into RAG Pipelines: \\nThe main contribution of this work is to seamlessly integrate prompt compression into the \\nRAG pipeline, which is centered around retrieval and general purpose summarization. This \\nintegration makes the pipeline a token optimized, LLM ready system by: \\n● A two stage compression process – first, an extractive stage to extract the best \\nsentences from given chunks as answers to the query, and second, an abstractive \\nstage to compress and refine the extracted information. \\n● Making token optimization a central component to embed, while maintaining the \\naccuracy of LLM prompts and keeping them under token limits. \\nApplications: This contribution advances beyond the state of the art in RAG research by \\noptimizing the pipeline for relevance (via retrieval) as well as token efficiency to be \\nsuitable for cost sensitive applications involving LLMs. \\n2. Token-Efficient Prompt Construction: \\nThe project presents a new methodology to balance between compression and accuracy using \\nmultiple evaluation metrics such as compression ratio, token savings, and BERTScore accuracy. \\nBy doing so, this contribution ensures that the compressed prompt. \\n● Keeps the key information necessary for the accurate responses. \\n● Reduces redundancy of and irrelevance to the content so that tokens are used as little as \\npossible. \\nUnlike traditional summarization systems that typically come up with long length outputs, this \\nproject presents a compression framework tailor made for LLM constraints for advancement.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 14, 'page_label': '15'}, page_content='3. Enhanced Retrieval through Dense Vector Representations: \\nThis project helps with advancements in retrieval techniques by using FAISS (Facebook \\nAI Similarity Search) and Sentence -BERT to retrieve semantically relevant chunks of \\ninformation from the database using user queries. \\n● With smaller, contextually meaningful portions of text known as retrieved chunks, \\nthey are more efficient to process downstream and compress than complete \\ndocuments. \\nPrecision: This project increases the precision of retrieval by focusing on retrieving \\ncontextually relevant chunks, and consequently, less information needs to be compressed. \\n4. Evaluation Framework for Prompt Compression in RAG Pipelines: \\nA multi metric evaluation framework for the performance of the prompt compression \\nprocess is developed in the project. The framework evaluates: \\n● Measuring the efficiency with which the information is compressed, i.e. token \\nsavings. \\n● Comparison of the original text size vs. the final compressed prompt. \\n● BERTScore/ROUGE scores: Maintaining the meaning of the compressed output. \\nApplication: The framework also enables future researchers to identify the appropriate \\nbalance between token efficiency and response quality in RAG systems. \\n \\n1.6.2 Practical Contributions \\n1. Efficient Token-Optimized LLM Prompts for Real-World Use: \\nIncorporating prompt compression to the RAG pipeline, the system creates \\ncompact prompts, limited to the minimum tokens to maintain the prompt \\nintelligibility and provide enough context for correct LLM responses without using \\nmore than necessary. As a resu lt, the cost is reduced and query efficiency is \\nimproved when querying large language models like GPT-3 or ChatGPT. \\n2. Scalable Integration of RAG Pipelines in Various Domains: \\nThe architecture of the system is scalable and adjustable so it can be applied to more \\nthan just the health care industry. This provides a way of efficiently compressing \\nlarge scale textual datasets such as:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 15, 'page_label': '16'}, page_content='Legal documents: Compressing case summaries. \\nFinancial reports: Summarizing key financial metrics and performance indicators. \\nScientific reports: Extracting and compressing key finds and conclusions from \\nscientific research papers. \\nApplication areas: This generalizable system can be directly applied to any industry \\nneeding concise, accurate summaries for decision making. \\n3. User-Friendly Interface for Querying and Compression: \\nThe project offers an interactive Streamlit interface to users for submitting queries \\nand receiving compressed, token efficient responses in real time. It is a practical \\nand easy to use solution that can be interacted with by users without technical \\nbackground. \\nBenefits: The interface fills the gap between technical NLP models and non-expert \\nusers by offering a simple query response mechanism. \\n4. Cost-Effective Use of LLMs: \\nFor LLMs based on tokens, by reducing the number of tokens of inputs, the system \\nsaves costs when interacting with token based LLMs such as GPT -3. Low cost of \\noperation is a benefit to both large enterprises and small organizations alike, while \\ncontinuing to provide access to high quality, AI driven responses. \\nToken overload:  Organizations can avoid spending prohibitively high costs on \\ntoken overload when scaling the use of LLMs.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 16, 'page_label': '17'}, page_content='1.7 Research Aim \\nThe goal of this work is to build a Retrieval Augmented Generation (RAG) pipeline to retrieve, \\ncompress and optimize unstructured large scale drug review data for interaction with large \\nlanguage models (LLMs) using dense retrieval and prompt compression. \\nThe project seeks to achieve: \\n● Dense vector based methods to efficiently retrieve relevant information using dense vectors \\nto make semantically accurate matches for user queries. \\n● Two stage approach (extractive and abstractive compression) of token efficient \\ncompression of retrieved content without compromising accuracy or key information. \\n● User friendly interface, real time interaction with concise and actionable responses for the \\npatients and healthcare professionals. \\nTherefore, the research will enable meeting this goal, which will tackle key challenges of working \\nwith large scale textual data, minimizing token overhead, and performing cost effective and \\naccurate querying of LLMs such as GPT-3 or ChatGPT. \\n \\n \\n1.8 Research Objectives \\n \\n \\nObjective  Description Learning Outcomes \\nLiterature Survey - To explore current \\nadvancements in Retrieval-\\nAugmented Generation \\n(RAG) pipelines and identify \\ngaps in existing systems. \\n \\n- To analyze compression \\ntechniques (both extractive \\nand abstractive) and their \\napplications in token -efficient \\nNLP systems. \\n \\n- To review previous research \\non dense retrieval (FAISS)  \\nand its integration with \\nsummarization systems. \\n- To select the appropriate \\nLO1, LO2, LO4'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 17, 'page_label': '18'}, page_content='retrieval models, \\ncompression techniques, and \\nevaluation metrics  for the \\nproject. \\nRequirement Analysis - To gather requirements from \\nhealthcare professionals, \\nresearchers, and technical \\nusers regarding the retrieval \\nand summarization of large \\nmedical datasets. \\n \\n- To define functional and \\nnon-functional requirements \\nrelated to retrieval speed, \\ntoken savings, and accuracy. \\nLO3, LO6 \\nDesign - To design the architecture for \\na dense retrieval and prompt \\ncompression pipeline , \\nintegrating FAISS-based \\nretrieval and a two -stage \\ncompression module. \\n \\n- To define the flow of \\ninformation from user query \\ninput to LLM -optimized \\nprompt generation. \\n \\n- To design evaluation metrics \\nfor assessing the performance \\nof token savings, \\ncompression ratio, and \\naccuracy. \\nLO3, LO5 \\nDevelopment -To implement the dense \\nretrieval system using FAISS \\nand Sentence-BERT to return \\nsemantically relevant chunks. \\n \\n- To develop and integrate the \\ntwo-stage compression \\nmodule (extractive + \\nabstractive) using BERT and \\nBART models. \\nLO7'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 18, 'page_label': '19'}, page_content='Testing - To create test plans for \\nevaluating the system’s \\nperformance based on \\ncompression ratio, token \\nsavings, retrieval accuracy, \\nand response time. \\n \\n- To conduct unit testing for \\nindividual components \\n(retrieval, compression) and \\nintegration testing for the \\noverall pipeline. \\nLO8 \\nEvaluation - To evaluate the system using \\nBERTScore, ROUGE, \\ncompression ratio, and \\nperplexity metrics. \\n \\n- To demonstrate the \\ndeveloped system to domain \\nexperts and gather feedback \\nthrough a demo session or viva \\npanel. \\nLO9 \\nTable 2 Research Objectives \\n \\n1.9 Novelty \\n1.9.1 Novelty of the Problem \\nThe problem addressed by this project is not merely retrieval or summarization but involves the \\noptimization of prompts for large language models (LLMs) through efficient compression. This \\nproblem is unique because: \\n● Traditional RAG systems primarily focus on retrieving and summarizing information \\nwithout explicitly optimizing token usage for LLMs like GPT-3 or ChatGPT. \\n● The challenge lies in balancing information retention and token reduction within the \\nconstraints of token -based models. This problem requires a novel approach to select, \\ncompress, and rephrase information while retaining its semantic integrity. \\nBy defining the problem in terms of prompt optimization for token efficiency , this project \\naddresses a key gap in existing research where token savings and cost reduction have been \\nunderexplored in LLM-based applications.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 19, 'page_label': '20'}, page_content='1.9.2 Novelty of the Solution \\nThe solution presented by this project is novel in its hybrid design that integrates dense retrieval \\nwith two-stage prompt compression. Key innovative aspects include: \\n1. Seamless Integration of Retrieval and Compression: \\n○ The project goes beyond conventional retrieval systems by integrating dense \\nretrieval using FAISS with two-stage prompt compression. \\n○ This integration enables the system to retrieve semantically relevant chunks and \\ncompress them into token -efficient prompts, making it a unique solution for real -\\ntime LLM interactions. \\n2. Two-Stage Compression Pipeline: \\n○ The system combines extractive compression (using BERT) to select key sentences \\nand abstractive compression (using BART) to refine and further compress the \\nselected content. \\n○ Unlike traditional summarization techniques, which either extract or paraphrase \\ninformation, this hybrid approach ensures both token efficiency and semantic \\ncompleteness. \\n3. Token Optimization as a Central Goal: \\n○ Most summarization techniques generate human -readable summaries but do not \\nexplicitly optimize for token constraints imposed by LLMs. \\n○ This project introduces token savings and compression ratio as key performance \\nmetrics, ensuring that the final output is both concise and informative. \\n \\n  \\n \\n \\n \\n \\n1.9.3 Novelty of the Methodology \\n1. Application of Dense Vector Retrieval (FAISS) to Generate Compressed Prompts:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 20, 'page_label': '21'}, page_content='● The project applies FAISS-based dense retrieval not just to retrieve full documents but to \\nextract contextually relevant knowledge chunks that serve as input to the compression \\npipeline. \\n● This methodology ensures that the retrieved content is already relevant and focused, \\nreducing the need for excessive filtering and summarization. \\n2. Multi-Metric Evaluation of Compression: \\n● The project employs a comprehensive evaluation framework  combining multiple \\nmetrics, including: \\n○ Compression ratio: To measure the reduction in token count. \\n○ ROUGE and BERTScore: To ensure semantic and contextual accuracy. \\n○ Perplexity: To measure the fluency of the compressed prompt. \\n● This multi-metric approach is novel in the context of RAG pipelines and can be adopted as \\na best practice for future systems involving prompt construction and optimization. \\n \\n \\n \\n \\n \\n \\n1.10 Chapter Summary \\nThis chapter introduced the core problem of efficiently retrieving and compressing large -scale, \\nunstructured drug review data for token-optimized interactions with large language models \\n(LLMs). The project aims to address the limitations of current retrieval and summarization \\nsystems by integrating prompt compression into a Retrieval-Augmented Generation (RAG) \\npipeline. \\nThe problem arises from the inefficiency of manually processing large datasets and the token \\nconstraints of LLMs  like GPT-3, which require optimized inputs to deliver cost -effective and \\naccurate responses. The research gap identified in this chapter highlights the lack of systems that \\nsimultaneously address retrieval efficiency and token savings through compression.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 21, 'page_label': '22'}, page_content=\"Chapter 2: Requirements Specification \\n2.1 Chapter Overview \\nThe present chapter deals with the elaboration of the overall requirement gathering process for the \\ngiven research project, from the very core of research to prototype development. To start off, the \\nidentification and diagramming of stakeholders in the pro posed system, their roles, and their \\nrelations with the help of graphs is performed. After which discussion and analysis of the various \\nrequirement elicitation techniques which may be used, by selecting in detail, is presented. The \\nelicited requirements ar e then represented in tabular format, use case diagrams along with their \\ndescriptions are developed. Finally, the conclusions drawn from the requirement elicitation process \\nare interpreted and summarized. \\n \\n2.2 Rich Picture Diagram \\n \\nThe objective of a rich picture diagram is to be able to illustrate the relationships which would exist \\nbetween the proposed system and its wider environment. These entities may extend beyond the \\ntertiary relationships to the system's own domain. Also, thi s rich picture diagram Also \\ndemonstrates potential threats and vulnerabilities that may affect the proposed system due to \\nactivities of malicious actors and lawful competitors alike.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 22, 'page_label': '23'}, page_content='Figure 1 Rich Picture Diagram \\n \\n \\n2.3 Stakeholder Analysis \\n \\n \\n2.4 Requirement Elicitation Methodologies \\nRequirement Elicitation is a critical step of software development which is all about acquiring the \\nrequirements for a software project who enables the developers gain a bird’s eye view of \\nappreciation of what it is, what it seeks: to achieve, its mission and vision. The tables below are a \\nbrief profile of the selected requirement elicitation methods and rationale with a focus on the \\nmerits/benefits of each certain procedure and cons. \\n \\nTechnique 1 – Interviews \\nSome interviews were useful in establishing the current state of the issues affecting efficiency'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 23, 'page_label': '24'}, page_content='in handling LLM’s and prompt processing. The importance of the parameters for quantifying \\nsuch as accuracy, response time, and token usage and domain experts assisted in the \\nidentification of possibilities for compression.  \\nTechnique 2 - Literature Review \\nThe Literature Review offered insights into the deficiencies on current LLM solutions and \\nprovided points at which timely compression would be of value over the efficiency of the \\nmodel. By reviewing the documentation of models such as GPT-3, LLama2 and BERT it was \\neasier to pinpoint areas where compression techniques could be integrated. \\nTechnique 3 - Brainstorming Sessions \\nThe concept generation helped in group thinking and was useful in coming up with a novel \\nplan of managing token issues and handlings such as maintaining essential context \\ninformation. This method fostered innovativeness and was also such that enabled successive \\nprototyping of concepts. \\nTable 3 Requirement Elicitation Methodologies \\n \\n \\n \\n \\n \\n2.5 Findings from Elicitation \\n2.5.1 Literature Review \\n \\nCitation Findings  \\nBrown et al., 2020; Devlin et al., 2019  Prior large language models (LLMs), including \\nGPT-3 and BERT, face some difficulty in \\naddressing the problems involving long inputs, \\nand the trade -offs between speed and \\ncapability. The majority of existing models is \\ndesigned to provide the most accurate a nd \\nrelevant output, but there is a number of \\ndrawbacks when using it with large inputs.  \\nSanh et al., 2019; Jiao et al., 2020  Experiments in the area of NLP’s timely \\ncompression revealed that it is important to \\npreserve the context to relevant and coherent \\nresults. Although to increase the speed of the \\nprocess such a reduction of tokens as pruning'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 24, 'page_label': '25'}, page_content='or distillation often causes the loss of highly \\nimportant contextual information which \\nfurther influences the relevance and accuracy \\nof the retrieved answers. \\nLewis et al., 2020; Raffel et al., 2020  Studies involving BART and T5 show that it is \\npossible to minimize the length of the input by \\npre-summarizing the longer text before passing \\nit to the LLMs. These models assist in \\nshrinking the input size but then may lose many \\ndetails in solving a problem , resulting into \\neither a partial or an erroneous one. \\nTable 4 Litreature Review \\n \\n4.5.2 Interviews \\n \\nCodes Themes Conclusions \\nPrompt Compression, \\nInformation Preservation \\nResearch Problem The reviewed literature and \\ndiscussions emphasized that \\nprompt compression should \\nretain essential information to \\nmaintain LLM response \\nquality. Stakeholders agreed \\nthat striking a balance between \\ntoken savings and context \\npreservation is critical in RAG \\npipelines. \\nToken Efficiency, Reduced \\nQuery Costs \\nResearch Gap Research showed that token \\nreduction stands as a primary \\noptimization technique for \\nNLP although most existing \\nRAG pipelines do not use \\nadaptive compression \\nmethods based on question \\ndifficulty level. This project \\nfills the existing gap through \\noptimized t oken management \\nfor questions and retrieved \\ndocuments. \\nAbstractive/Extractive Methodology Professionals advised using a'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 25, 'page_label': '26'}, page_content='Summarization, Multi -step \\nCompression \\ntwo-step summarization \\nmethod that combines \\nextractive with abstractive \\nmethods when working with \\npharmaceutical assessment \\ndata. A two-tier process using \\nextractive then abstractive \\napproaches ensures efficient \\ncompression without \\nsacrificing essential me dical \\ninformation or facts. \\nWebMD Dataset, Chunking \\nStrategy \\nDatasets Participants chose the \\nWebMD Drug Reviews \\ndataset together with their \\nchunking strategy as the \\noptimal combination for RAG \\nimplementation. Researchers \\nagreed that vector storage and \\nretrieval perform best when \\nparticipants conduct proper \\npre-processing while applying \\nchunking methods. \\nEmbedding Models, \\nVectorization Techniques \\nSystem Design Integrating vectorization \\ntechniques like Sentence -\\nBERT and FAISS for fast and \\naccurate retrieval was \\nhighlighted as crucial. \\nStakeholders stressed the \\nimportance of indexing vector \\nembeddings efficiently to \\nreduce retrieval latency. \\nFinal Prompt Construction, \\nCombined Queries \\nEvaluation Metrics Evaluating the combined \\nprompt (original user query + \\ncompressed retrieved \\ninformation) using token \\nefficiency, retrieval accuracy, \\nand final LLM response \\nrelevance ensures \\ncomprehensive assessment of \\nproject outcomes. \\nTable 5 Interviews'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 26, 'page_label': '27'}, page_content='2.6 Context Diagram \\nThe Context Diagram gives a general description of Dynamic Prompt Compression System for \\nLLMs and shows the ways in which DP CSS LLMs communicates with outside entities. On this \\ndiagram the system is shown in the middle with the end-users and the stakeholders placed around \\nit indicating the inputs they submit and the outputs they get. \\nEnd Users (NLP Engineers/Data Scientists): Input plain text data to the system and obtain small \\ntext data that are efficient when fed into LLMs. \\nProject Owner: Provides needful information for alteration of system and gets statistic data to \\nassess effectiveness of used system.  \\nQuality Assurance Team: Gives information about the performance of the system and receives \\nevaluation logs for the quality check.  \\nThis diagram assists in identifying the key duties and the major tasks of every stakeholder; at the \\nsame time this shows how the information between the stakeholders and the system may be \\nexchanged effectively and cohesively to define the project’s scope and interactions. \\n \\n \\nFigure 2 Context Diagram \\n \\n2.7 Use Case Diagram and Descriptions'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 27, 'page_label': '28'}, page_content='The following diagram shows the use-cases tied to the approaches that involve interactions within \\nthe system and its most important players. Furthermore, interactions between the use cases \\nwithin the have also been suggested for clarity in the system have also been indicated for better \\nunderstanding. \\n \\n2.7.1 Use Case Diagram \\n \\n2.7.2 Use Case Descriptions \\n \\n \\n \\n \\n \\n \\n2.8 Functional and Non-Functional Requirements \\n2.8.1 Functional Requirements (FR) \\nThese requirements define the core functions that the system must perform to achieve its \\nobjectives. \\n \\nID Requirement Priority (MoSCoW) Description \\nFR1 The system shall \\naccept user queries \\nthrough the front-end. \\nMust Have Users can input \\nquestions related to \\ndrugs or treatments. \\nFR2 The system shall \\nretrieve relevant \\nchunks from the \\nvectorized database. \\nMust Have The retrieval should \\nbe based on FAISS \\nand embedding -based \\nsimilarity search. \\nFR3 The system shall \\ncompress retrieved \\ndata using extractive \\nand abstractive \\nmethods. \\nMust Have Compress the \\nretrieved chunks \\nusing the multi -step \\ncompression \\napproach. \\nFR4 The system shall \\ncombine the user \\nquery and compressed \\ncontent into a final \\nprompt \\nMust Have The combined prompt \\nis formatted for \\noptimal input to the \\nLLM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 28, 'page_label': '29'}, page_content='FR5 The system shall pass \\nthe final prompt to an \\nLLM to generate \\nresponses. \\nMust Have Utilize an OpenAI \\nAPI or other LLM for \\nanswer generation. \\nFR6 The system shall \\nprovide an option for \\nusers to copy the final \\ncompressed prompt. \\nShould Have Users can copy the \\ncompressed prompt \\nfor further use. \\nFR7 The system shall \\ndisplay relevant drug \\nnames alongside the \\nsummarized \\nresponses. \\nShould Have Provide drug context \\nwithin the final output \\nto ensure clarity. \\nFR8 The system shall log \\nuser queries and \\nresponses for \\nperformance \\nevaluation. \\nCould Have Maintain a log to \\nanalyze and refine the \\nretrieval and \\ncompression process. \\nTable 6 Functional Requirements \\n2.8.2 Non-Functional Requirements (NFR) \\n \\nID Requirement Priority (MoSCoW) Description \\nNFR1 The system shall \\nprovide responses \\nwithin 5 seconds of \\nquery submission. \\nMust Have Ensures acceptable \\nsystem response time \\nfor user interaction. \\nNFR2 The system shall \\nmaintain high \\nretrieval accuracy \\nwith minimal token \\nloss. \\nMust Have The token \\ncompression must \\npreserve important \\ncontext for generating \\naccurate responses. \\nNFR3 The system shall \\nsupport scalability \\nwith large medical \\ndatasets. \\nShould Have The system must \\nhandle large datasets \\n(e.g., WebMD \\nreviews) efficiently \\nfor scalable operation. \\nNFR4 The system shall be Should Have Simple and intuitive'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 29, 'page_label': '30'}, page_content='user-friendly and \\neasy to navigate for \\nnon-technical users. \\ninterface design to \\nensure ease of access \\nto features. \\nNFR5 The system shall \\nensure data security \\nand privacy. \\nMust Have User queries and \\nretrieved data should \\nbe protected from \\nunauthorized access. \\nNFR6 The system shall \\nallow for easy \\nupdates to embedded \\nmodels and \\nsummarization \\ntechniques. \\nCould Have Modular architecture \\nto allow replacing \\nmodels without \\naffecting the overall \\nsystem. \\nNFR7 The system shall \\nmaintain minimal \\ncomputational \\noverhead during \\ncompression. \\nShould Have Ensure that the \\ncompression process \\ndoes not introduce \\nsignificant delays. \\nNFR8 The system shall \\nprovide high \\navailability and \\nreliability. \\nCould Have Ensure minimal \\ndowntime and \\nconsistent \\nperformance across \\nuse cases. \\nTable 7 Non - Functional Requirements \\n \\n2.9 Chapter Summary \\nThe chapter on the Software Requirement Specification has given an understanding of the \\nfunctional and non-functional requisition of the system, how these requirements are elicited, and \\nthe procedures as well as tools and techniques that have been adopted to meet the stakeholder’s \\nneeds. The system requirements were prioritised according to the MoSCoW principle to identify \\nwhat is must have for the success of the system.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 30, 'page_label': '31'}, page_content='Chapter 3: Design \\n3.1 Chapter Overview \\nThe design determinations for developing an appropriate system architecture will receive detailed \\nanalysis in this chapter. The design of the proposed system stems from requirements identification \\nin an earlier chapter. First, the The identified design goa ls will be displayed in a table structure \\nwhile high-level design together with low level design and system process flow chart along with \\nUI wireframes will be presented.The creation of system process flow charts together with UI \\nwireframes stands alongsid e other associated design diagrams. A complete rationale backs each \\ndecision during design. \\n3.2 Design Goals \\n \\nDesign Goal Description \\nPerformance Research Component : The integration of \\nprompt compression into RAG pipelines must \\ndemonstrate improved efficiency in generating \\naccurate responses while optimizing token \\nusage. The system should minimize the \\nnumber of tokens while maintaining response \\nrelevance. \\n \\nPrototype Component: The prototype should \\nensure that prompt compression and retrieval \\ndo not introduce significant latency, aiming for \\nresponse times within user -acceptable limits \\n(e.g., under 5 seconds). \\nAdaptability The system should be adaptable to different \\nknowledge bases and datasets. While this \\nproject focuses on the WebMD Drug Review \\nDataset, the architecture should allow easy \\nextension to other medical or domain -specific \\ndatasets without requiring significant redesign. \\nUsability Since the application targets both technical and \\nnon-technical users, the user interface (via \\nStreamlit) should be clean, minimalistic, and \\nintuitive. Features such as copyable \\ncompressed prompts, easy input of user \\nqueries, and accessible feedback mechanisms \\nshould be emphasized to ensure a positive user \\nexperience.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 31, 'page_label': '32'}, page_content='Scalability The RAG pipeline should be capable of scaling \\nhorizontally to handle large medical datasets \\n(e.g., millions of records). The FAISS index \\nand vectorization processes should efficiently \\nretrieve relevant information even as the \\ndataset grows. \\nCorrectness Compression Accuracy : The compressed \\nprompt must preserve key facts and important \\ncontext to ensure that LLM responses are \\ncorrect and contextually appropriate. \\nInformation Retrieval : Ensure the retrieval \\nmechanism correctly identifies relevant \\nreviews and minimizes irrelevant or redundant \\ndata. \\nMaintainability  \\n \\n \\nThe system architecture should be modular, \\nallowing for future updates or replacements \\nof the embedding models, retrieval \\nmechanism, or compression strategies \\nwithout affecting the overall system. \\nDocumentation and code structure should \\nsupport ease of mai ntenance and future \\nimprovements.  \\nSecurity and Privacy Given that the system involves sensitive \\nmedical data, it is important to follow best \\npractices for data security, ensuring that \\nqueries, retrieved data, and responses are \\nproperly encrypted and protected from \\nunauthorized access. The design should also \\nensure that user interaction data is handled in \\ncompliance with data privacy regulations. \\nTable 8 Design Goals \\n \\n \\n \\n3.3 System Architecture Design \\n \\n3.3.1 Architecture Diagram'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 32, 'page_label': '33'}, page_content='The project demands a tiered model which separates presentation from logic from data tiers. The selection \\nof a system architecture that separated physical components between tiers occurred because of the project \\nrequirements. The following diagram the different components which exist within their corresponding tiers. \\nThe Presentation tier deals User Interface components of the system receive input from end users while \\nData tier manages data storage and retrieval operations. The data management system throug h the Logic \\ntier connects presentation and data functions by enabling system functionality functionalities of the system. \\n \\n \\nFigure 3 Architecture Diagram \\n \\n \\n \\n \\n \\n \\n3.3.2 Discussion of Tiers \\nPresentation Tier'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 33, 'page_label': '34'}, page_content='User Input Box: \\n● Description: This is the interface where the user enters their query. It serves as the main \\ninteraction point between the user and the system. \\nSubmit Button: \\n● Description: A button to initiate the process. When clicked, it triggers the query processing \\nand retrieval workflow. \\nFinal Display Box: \\n● Description: Displays the summarized response generated by the system, combining the \\noriginal query with relevant compressed data. \\nDownload Button: \\n● Description: Allows users to download the final prompt containing the query and retrieved \\nsummary. \\nCopy Button: \\n● Description: Enables users to copy the final prompt to the clipboard for use in other \\napplications. \\n \\nLogic Tier \\nQuery Processing Module: \\n● Description: Converts the user’s input into vector form using an embedding model. It \\nensures the query is properly formatted for search and retrieval. \\nRetriever Module: \\n● Description: Searches the FAISS index to find the most relevant preprocessed chunks \\ncorresponding to the user query. \\nHybrid Compression Module: \\n● Description: Applies extractive and abstractive summarization techniques to compress \\nthe retrieved chunks into a concise, informative summary. \\nEvaluation Module:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 34, 'page_label': '35'}, page_content='● Description: Evaluates the output of the system using metrics such as ROUGE, \\nBERTScore, and Recall @ K to ensure quality and effectiveness of the retrieved and \\ncompressed data. \\n \\nData Tier \\n1. WebMD Drug Reviews Dataset: \\n○ Description: Contains the raw data, including drug reviews, side effects, dosage \\ndetails, and user experiences. \\n2. Preprocessed Review Chunks: \\n○ Description: The dataset is split into smaller, manageable chunks for efficient \\nprocessing and embedding. \\n3. Embedding Storage: \\n○ Description: Stores the vector representations of the review chunks generated \\nusing Sentence-BERT. These vectors are used for efficient similarity searches. \\n4. FAISS Index: \\n○ Description: An optimized search index that facilitates fast retrieval of the most \\nrelevant chunks based on the query’s vector representation. It acts as the core \\nretrieval engine for the system. \\n \\n \\n \\n3.4 Detailed Design \\n● Purpose: Provide an in-depth look at system components. \\n● Content: \\no Use diagrams like class, sequence, or flow diagrams. \\no Explain how each component supports the system’s goals. \\n \\n3.5 Algorithm Design \\nThis section presents the design of the key algorithms used in the project. The algorithms focus on \\nprocessing user queries, retrieving relevant review chunks using the FAISS index, applying hybrid \\ncompression, and generating optimized responses.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 35, 'page_label': '36'}, page_content='Key Algorithms and Pseudocode: \\n1. Algorithm: Query Embedding and Retrieval using FAISS Index \\nConvert the user’s natural language query into an embedding and retrieve the most relevant \\nreview chunks using FAISS similarity search. \\n \\nFigure 4 Query Embedding \\n2. Algorithm: Hybrid Compression \\nCompress the retrieved chunks by combining extractive and abstractive summarization. \\nFirst, extract sentences containing key phrases, and then refine the summary using a \\nlanguage model. \\n \\nFigure 5 Hybrid Compression \\n3. Algorithm: Final Prompt Generation \\nCombine the user query with the compressed information to generate a final prompt for the \\nLLM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 36, 'page_label': '37'}, page_content='3.6 UI Design Wireframe \\n \\nFigure 7 UI Wireframe \\nFigure 6 Prompt Generation'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 37, 'page_label': '38'}, page_content='3.7 Chapter Summary \\nThe chapter provided an in -depth description of system design including the methodologies that \\nwould be used during the implementation of the proposed solution. Design goals led the \\ndevelopment of high-level and low-level architectural components which were structured through \\nrelevant design diagrams. The selected software design paradigm received justification while the \\nsystem design included supporting diagrams which displayed components and data flow and \\nprocess flow and user interfaces. System implementation details will be discussed in the following \\nchapter according to design outline specifications.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 38, 'page_label': '39'}, page_content='Chapter 4: Implementation \\n4.1 Chapter Overview \\nThe author provides comprehensive documentation regarding every aspect of the implementation \\nworkflow for the designed prototype. The system architecture advanced through combination of \\nknowledge derived from the literature review and requirement elicitati on phases, suitable \\ntechnologies and development frameworks have been selected. The selected technological choices \\nreceive adequate justification. The core functionality implementation details receive support \\nthrough code examples that accompany the provided information. \\n \\n \\n4.2 Technology Selection \\n4.2.1 Technology Stack \\nThe following figure represents the technologies selected to for the implementation and \\nfunctionality of the designed 3-tier architecture. \\n \\nPresentation Tier \\n \\n \\nLogic Tier'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 39, 'page_label': '40'}, page_content='Data Tier  \\n \\n \\nTable 9 Technology Stack \\n4.2.2 Dataset Selection \\nSeveral specialized data collections for drug reviews and user queries were selected from literature \\nreview findings and requirement gathering to support information retrieval and compression \\nfunctions along with language modeling. \\n \\nDataset Type Purpose \\nWebMD Drug Reviews \\nDataset \\nSpecialized dataset of drug \\nreviews \\nThe database functions as the \\nmain drug review platform \\nwhich collects user feedback \\nabout medication conditions \\nand performance together with \\nreported side effects. The \\nreviews will undergo \\nsegmentation followed by \\nvectorization so they can be \\nretrieved d uring query \\nexecution. \\nUCI ML Drug Review Dataset Generalized dataset on drug \\nreviews \\nThe system provides \\nsupplementary information to \\nenlarge search parameters and \\nachieve better query retrieval \\nperformance. The method'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 40, 'page_label': '41'}, page_content='delivers retrieval results that \\ninclude comprehensive \\nfindings which maintain their \\nvalidity across different drug \\nconditions. \\nKaggle Health -Related \\nDatasets \\nHealth-specific user feedback The system offers additional \\ndomain-specific datasets that \\nenable the retrieval pipeline to \\nexpand its knowledge base \\nfrom more user experiences \\nand medical review \\ndocuments. \\nPre-trained Sentence \\nEmbedding Models (e.g., all -\\nMiniLM-L6-v2) \\nEmbedding models The system converts all user \\nqueries and retrieved chunks \\ninto vectorized formats which \\nallows FAISS indexing to \\nperform similarity -based \\nquery matching. \\nSumy-based Summarization \\nOutputs \\nCompressed summary of \\nretrieved data \\nThe system performs efficient \\nprompt compression by using \\nextractive and abstractive \\nsummarization methods \\nbefore delivering the prompt \\nto the LLM. \\nTable 10 Dataset Selection \\n \\n \\n4.2.3 Programming Languages \\n \\nProgramming Language Reasoning \\nPython Python is chosen as the primary programming \\nlanguage for building the core system, \\nincluding data preprocessing, chunking, \\nvectorization, retrieval, and compression. Its \\nextensive library support (e.g., \\nSentenceTransformers, faiss, \\npandas, and transformers) and active'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 41, 'page_label': '42'}, page_content='community make it ideal for machine learning \\nand natural language processing tasks. \\nReact (JavaScript) The front-end interface of the application uses \\nReact for user interaction improvement. The \\ncomponent-based structure of this design \\nfacilitates automatic content delivery which \\nenables efficient display of retrieved \\ncompressed prompts in real-time fashion. \\nHTML & CSS The front -end components of the system \\nreceive their structure and style design from \\nBootstrap to maintain a clean interface that is \\neasy to use and accessible to users. \\n \\n \\nTable 11 Programming Languages \\n4.2.4 Libraries/Toolkits \\nBased on the selected programming languages, development frameworks, and system architecture, \\nthe following libraries and toolkits were chosen to support the development of the RAG pipeline \\nwith prompt compression functionality. These libraries enhance the  system’s ability to perform \\nretrieval, compression, vectorization, and efficient front-end interactions. \\n \\nLibrary / Toolkit Rationale \\nPyTorch  A machine learning model utilizing \\nPyTorch was chosen to develop and optimize \\nany extra models required for prompt \\ncompression or vectorization functions. The \\ndynamical computation graph in combination \\nwith strong support capabilities makes \\nPyTorch suitable for research-based work. \\nSentence-BERT This library, based on PyTorch and Hugging \\nFace’s transformers, is used for query encoding \\nand dataset vectorization. It enables the \\ngeneration of dense vector embeddings for \\neffective retrieval. \\nFaiss Faiss is crucial for efficiently indexing and \\nsearching through vectorized representations \\nof the drug review dataset, enabling fast \\nretrieval of relevant knowledge chunks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 42, 'page_label': '43'}, page_content='NumPy Used for performing numerical and matrix -\\nbased operations, including embedding \\nmanipulation, vector computations, and other \\nmathematical tasks required in the data \\nretrieval and summarization process. \\nPandas Pandas is used for handling, filtering, and \\nprocessing the drug review dataset. It allows \\neasy manipulation of tabular data and chunk \\ncreation necessary for the retrieval pipeline. \\nSpaCy SpaCy is used for sentence tokenization and \\nsplitting during extractive and abstractive \\ncompression. It supports linguistic analysis and \\nis useful in refining tokenized text for better \\ncompression. \\nSumy The Sumy library is utilized for performing \\nextractive summarization through algorithms \\nlike LSA. It assists in reducing the size of \\nretrieved chunks before combining them into \\nthe final prompt. \\nScikit-Learn Scikit-Learn is employed for data pre -\\nprocessing, vector manipulation, and \\npotentially integrating additional evaluation \\ntechniques for compression effectiveness. \\nStreamlit Streamlit simplifies the creation of an \\ninteractive front -end interface for user input, \\ndisplaying retrieved results, and interacting \\nwith the underlying retrieval and compression \\nmodels. \\nTable 12 Library Toolkit \\n4.3 Core Functionalities Implementation \\nThe RAG Pipeline with prompt compression operates through a modular design that splits \\nresponsibilities between different modules to gather and condense appropriate information before \\ncreating the final prompt presentation. The system consists of fundament al modules with this \\nfollowing description: \\n \\nModule Purpose Relation to Functional \\nRequirements (Chapter 2)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 43, 'page_label': '44'}, page_content='Data Preprocessing This module \\n(download_dataset.py) \\nprepares the dataset by \\ncleaning, splitting, and \\ncreating vector embeddings of \\nreview chunks using \\nSentence-BERT. \\nEnsures that data is ready for \\nretrieval, supporting the \\nrequirement of efficient data \\nprocessing. \\nVector Database FAISS-based indexing \\n(vector_database.py) \\nto store and retrieve the \\nvectorized review chunks \\nefficiently. \\nSupports retrieval of top -k \\nrelevant chunks from large \\ndatasets. \\nUser Query Encoding Converts the user query into a \\nquery vector using Sentence -\\nBERT (user_query.py). \\nAllows retrieval of relevant \\nreview chunks in response to \\nuser input. \\nChunk Summarization and \\nCompression \\nApplies both extractive \\n(keyword-based) and \\nabstractive (BART -based) \\nsummarization to retrieved \\nchunks (user_query.py & \\nstreamlit_app.py). \\nCompresses retrieved data to \\nprovide a concise, context-rich \\nprompt. \\nStreamlit Frontend Provides a user -friendly \\ninterface where users can \\ninput queries and view the \\nsummarized output \\n(streamlit_app.py). \\nSupports user interaction and \\nvisual presentation of the \\ngenerated prompts. \\nTable 13 Core Functionality Implementation \\n \\nCode Structure \\n \\nThe code uses modular programming principles and follows key scripts which maintain \\nseparation of concerns and ensure code maintainability. \\n \\n1. Preprocessing and Data Preparation \\n \\n● Cleans the dataset (removes duplicates and nulls). \\n● Splits large reviews into manageable chunks. \\n● Generates and saves embeddings using Sentence-BERT.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 44, 'page_label': '45'}, page_content='2. Embedding Generation \\n \\n \\n \\n \\n \\n3. FAISS Index Initialization \\n \\n \\n \\n \\n4. Query Vectorization and Retrieval'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 45, 'page_label': '46'}, page_content='5. Summarization and Final Prompt \\n \\n \\n \\n \\n \\n4.4 User Interface Implementation \\n4.4.1 Frontend Development'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 46, 'page_label': '47'}, page_content='Streamlit served as the development framework for creating the application frontend through its \\nPython-based web application construction system. The application shows a focus on basic design \\nwith intuitive controls and provides detailed results to user requests. \\n \\nUI Element Description \\nText Input Box Users should enter their drug review -related \\nquestions or queries through a basic text entry \\nfield. \\nSubmit Button The \"Get Response\" button activates \\ninformation retrieval along with summary \\ngeneration after click activation. \\nFinal Prompt Display The output shows the combined prompt that \\nincludes both the user query and compressed \\ninformation retrieved from the sources. \\nCopy Prompt Button The application enables users to transfer the \\nfinal prompt output into a text file which they \\ncan utilize or document. \\nWarning/Validation Messages The interface shows alerts to users who \\nabandon input fields or submit non -valid \\nsearch terms. \\nTable 14 UI Elements \\n4.4.2 Backend Integration \\nThe backend is responsible for handling user queries, retrieving relevant information using the \\nFAISS index, and compressing the information using abstractive summarization. The interaction \\nbetween the frontend and backend is as follows: \\n1. User Input: The user submits a query via the input box on the frontend. \\n2. Query Processing: The backend encodes the user query using the Sentence-BERT model \\nand retrieves the most relevant chunks from the FAISS index. \\n3. Compression and Summarization: The retrieved chunks are processed by the backend’s \\nsummarization component, which generates a compressed and meaningful response. \\n4. Result Display: The final prompt is returned to the frontend and displayed for the user.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 47, 'page_label': '48'}, page_content='User Interface \\n \\n \\n \\n>> Next Page'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 48, 'page_label': '49'}, page_content='Figure 8 User Interface'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 49, 'page_label': '50'}, page_content='4.5 Challenges and Solutions \\nThe deployment of the RAG pipeline with prompt compression required handling multiple \\nobstacles which emerged during development. This section analyzes significant obstacles that \\nemerged during project implementation together with their project effect and the implemented \\nsolutions for optimization. \\n \\nChallenge Description Solution \\n Slow Query Execution The retrieval process using the \\nFAISS index initially \\nexhibited delays, especially \\nwhen handling large datasets \\nand complex user queries. \\nOptimized the FAISS index by \\nprecomputing and storing \\nembeddings efficiently. \\nReduced top -k search range \\nand experimented with \\ndistance metrics. \\nLarge Embedding File Size The vectorized embeddings \\n(stored in \\nembeddings.npy) \\nconsumed significant disk \\nspace and memory during the \\nretrieval process. \\nCompressed embeddings \\nusing dimensionality \\nreduction techniques (e.g., \\nPCA). Implemented chunk -\\nbased data loading to handle \\nmemory constraints. \\nSummarization Model \\nPerformance \\nThe abstractive \\nsummarization model \\n(facebook/bart-\\nlarge-cnn) initially \\nstruggled with long retrieved \\nchunks, resulting in \\nincomplete summaries. \\nApplied extractive \\ncompression using keyword \\nprioritization to reduce the text \\nbefore passing it to the \\nsummarization model. \\nInconsistent Query Results The results retrieved from the \\nFAISS index were sometimes \\ninconsistent due to \\nimbalanced or sparse review \\ncontent. \\nImproved dataset \\npreprocessing by splitting and \\nfiltering chunks for better \\nrelevance. Balanced training \\nusing diverse and complete \\nreview texts. \\nNLTK Tokenizer Errors Errors were encountered when \\ntokenizing long or irregular \\nreview texts using NLTK’s \\nsent_tokenize(). \\nUpdated the tokenization \\nprocess to handle irregularities \\nby combining NLTK with \\nSpacy’s robust sentence \\nsegmentation for fallback \\ncases.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 50, 'page_label': '51'}, page_content=\"High Latency in Streamlit \\nApplication \\nThe Streamlit frontend faced \\nperformance bottlenecks when \\nretrieving and displaying \\nresults in real time. \\nImplemented Streamlit \\ncaching mechanisms using \\n@st.cache and optimized \\nthe communication between \\nfrontend and backend using \\nasynchronous updates. \\nAbstractive Summarization \\nOutput Quality \\nSummarization often \\nproduced vague or overly \\ngeneric responses due to lack \\nof context from input chunks. \\nIntroduced a two -stage \\ncompression: extractive \\n(keyword-prioritized) \\nfollowed by abstractive \\nsummarization, ensuring \\nimportant details were \\nretained. \\nIntegration Issues Between \\nFrontend and Backend \\nCommunication between the \\nfrontend UI and backend \\nmodules sometimes failed due \\nto inconsistent data formats \\n(e.g., lists vs strings). \\nStandardized data exchange \\nformats between the frontend \\nand backend by ensuring that \\nall intermediate data structures \\nfollowed JSON or Pandas \\nDataFrames. \\n Dataset Quality and Noisy \\nReviews \\nThe WebMD Drug Reviews \\ndataset contained noisy data \\n(e.g., incomplete reviews, \\nirrelevant information). \\nCleaned the dataset by \\napplying preprocessing \\ntechniques such as stop -word \\nremoval, filtering duplicates, \\nand handling missing data \\nefficiently. \\nUser Interface \\nResponsiveness \\nEnsuring that the application \\nremained responsive and \\nusable on various devices and \\nscreen sizes was challenging. \\nDesigned a minimalistic UI \\nusing Streamlit with \\nresponsive design elements. \\nEnhanced user feedback \\nthrough warning messages \\nand status indicators. \\nTable 15 Challengers and Solutions \\n \\n4.6 Chapter Summary \\nThe project's implementation phase concentrated on designing and uniting essential components \\nfor the Retrieval -Augmented Generation (RAG) pipeline alongside prompt compression \\ntechniques. This chapter details the implementation process by describing technology choices and \\ndemonstrates how major modules operated alongside the resolution of encountered challenges.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 51, 'page_label': '52'}, page_content='Chapter 5: Testing \\n \\n5.1 Chapter Overview \\n \\nThis chapter explains the entire testing process in detail along with its essential role to establish \\nquality standards for the developed prototype. The testing process includes multiple elements \\nstarting from testing objectives to model testing through be nchmarking before conducting \\nfunctional and non-functional tests and module and integration tests and ending with identification \\nof testing limitations. This section will explore all the constraints which affect the testing \\nprocedure. \\n \\n \\n5.2 Testing Criteria \\n1. Functional Requirements Validation \\nTests Conducted: \\n● Query Submission: Verify that user inputs are correctly processed and encoded. \\n● Data Retrieval: Validate that the system retrieves the top-k relevant review chunks \\nfrom the FAISS index based on the user query. \\n● Prompt Compression:  Ensure that retrieved chunks are compressed correctly \\nthrough extractive and abstractive summarization. \\n● Prompt Generation: Confirm that the final prompt combines the user query and \\ncompressed information correctly and is ready for downstream LLM usage.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 52, 'page_label': '53'}, page_content='2. Non-Functional Requirements Evaluation \\n \\nNon-Functional \\nRequirement \\nDescription Metric Used Target Value \\nSpeed Measure the time \\ntaken to process \\nuser queries, \\nretrieve results, and \\ngenerate final \\nprompts. \\nAverage Response \\nTime \\n≤ 2 seconds \\nfor most \\nqueries \\nScalability Ensure the system \\ncan handle larger \\ndatasets without \\nsignificant \\nperformance \\ndegradation. \\nThroughput Testing Efficient response \\ntime for up to 1M \\nreview records. \\nReliability Ensure consistent \\noutput and robust \\nerror handling in \\ncase of data or \\nsystem failures. \\nSuccess Rate of \\nQueries \\n≥ 99% \\nsuccessful \\nresponses. \\nUsability Ensure that the \\ninterface is intuitive \\nand user-friendly. \\nUser Feedback \\nRating \\n≥ 4/5 based on \\nend-user \\ntesting. \\nTable 16 Non-Functional Requirements \\n3. Model Performance Metrics \\nThe retrieval and compression processes depend on model accuracy and relevance. \\nTherefore, model performance metrics are evaluated as follows: \\n \\nMetric Description Target \\nROUGE-1, ROUGE-2, \\nROUGE-L \\nMeasures overlap between \\nretrieved or compressed \\ninformation and expected \\noutputs. \\n≥ 0.5 average score.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 53, 'page_label': '54'}, page_content='BERTScore Measures the semantic \\nsimilarity between \\nretrieved/compressed \\nchunks and the gold -\\nstandard text. \\nPrecision ≥ 0.85, \\nRecall ≥ 0.80 \\nRecall @ k Measures how many of the \\nrelevant chunks are \\nretrieved within the top -k \\nresults. \\n≥ 80% of relevant \\nchunks retrieved. \\nCompression Ratio  \\n \\n \\nEvaluates how effectively \\nthe retrieved data is \\ncompressed while \\npreserving key \\ninformation.  \\nTarget ratio ≤ 10:1 \\nPerplexity (LLM \\nEvaluation) \\nMeasures how well the \\nprompt is understood by the \\ndownstream LLM. \\nAcceptable levels for low \\nperplexity. \\n \\n \\nTable 17 Model Performance Metrics'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 54, 'page_label': '55'}, page_content='Output Results: \\n \\n \\n \\n5.3 Functional Testing \\n \\nTest Case FR ID User Action Expected \\nOutcome \\nActual \\nOutcome \\nResult Status \\n1 FR1 User enters a drug-\\nrelated query (e.g., \\n\"What are the side \\neffects of \\nibuprofen?\") into \\nthe Streamlit input \\nbox and clicks \"Get \\nResponse.\" \\nThe system \\nprocesses the \\nquery, retrieves \\nrelevant review \\nchunks, and \\ndisplays the final \\ncompressed \\nprompt. \\nThe system \\nsuccessfully \\nprocessed the \\nquery, retrieved \\nrelevant \\nchunks, and \\ndisplayed the \\nfinal prompt. \\nPassed \\n2 FR2 User submits an \\nempty query by \\nclicking \"Get \\nResponse\" without \\nentering any input. \\nA warning \\nmessage is \\ndisplayed, \\nprompting the \\nuser to enter a \\nquery. \\nThe system \\ndisplayed a \\nwarning \\nmessage: \\n\"Please enter a \\nquery to get \\nstarted.\" \\nPassed \\n3 FR3 User submits a The top -10 most The system Passed'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 55, 'page_label': '56'}, page_content='valid query, and \\nthe system \\nretrieves and \\ncompresses the \\ntop-10 relevant \\nchunks. \\nrelevant chunks \\nare retrieved, \\ncompressed, and \\nincluded in the \\nfinal output. \\nsuccessfully \\nretrieved and \\nsummarized \\nthe top -10 \\nchunks with \\nrelevant drug \\nreviews. \\n4 FR4 User clicks the \\n\"Download Final \\nPrompt\" button to \\ndownload the \\ncompressed \\nprompt as a text \\nfile. \\nThe compressed \\nprompt is \\ndownloaded to \\nthe user’s device \\nas \\nfinal_promp\\nt.txt. \\nThe system \\nsuccessfully \\ndownloaded \\nthe file to the \\nuser’s device. \\nPassed \\n5 FR5 User enters a query \\ncontaining \\nkeywords like \\n\"side effects\" or \\n\"treatment\" and \\nsubmits it. \\nThe system \\nprioritizes \\nsentences \\ncontaining \\nkeywords and \\nuses them for \\nextractive \\nsummarization. \\nSentences \\ncontaining the \\nrelevant \\nkeywords were \\nprioritized and \\nincluded in the \\ncompressed \\nprompt. \\nPassed \\n6 FR6 User submits a \\nquery, and the \\nevaluation metrics \\nare computed after \\nthe final prompt \\ngeneration. \\nROUGE, \\nBERTScore, and \\nRecall @ k \\nmetrics are \\ndisplayed in the \\nStreamlit \\ninterface. \\nEvaluation \\nmetrics \\n(ROUGE, \\nBERTScore, \\nRecall @ k) \\nwere correctly \\ncalculated and \\ndisplayed in the \\nUI. \\nPassed \\n7 FR7 User submits a \\nquery, and the \\nsystem performs \\nend-to-end \\nexecution, from \\nquery input to \\nprompt display. \\nThe system \\nprocesses the \\nquery, retrieves \\nrelevant \\ninformation, and \\ndisplays the \\ncompressed \\nprompt. \\nThe system \\nsuccessfully \\nexecuted the \\nend-to-end \\nworkflow, \\ndisplaying the \\nprompt within \\nacceptable \\ntime. \\nPassed \\n8 FR8 User submits The system The system Passed'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 56, 'page_label': '57'}, page_content='multiple queries in \\nsuccession to test \\nsystem \\nresponsiveness and \\nperformance. \\nresponds within 5 \\nseconds for each \\nquery and \\nmaintains \\nconsistent results. \\nmaintained \\nconsistent \\nresponse times \\nand displayed \\naccurate \\ncompressed \\nprompts for \\neach query. \\nTable 18 Functional Testing \\n \\n5.4 Non-Functional Testing \\n5.4.1 Performance Testing \\nObjective: Evaluate the system’s response times under different loads, ensuring the query \\nprocessing and retrieval mechanisms perform within acceptable limits. \\n \\nTest Scenario Load Condition Expected \\nResponse Time \\nActual \\nResponse Time \\nResult Status \\nSingle user \\nquery \\n1 user submitting \\na query \\n≤ 2 seconds 1.8 seconds Passed \\nMultiple \\nconcurrent users \\n(5 users) \\nSimulate 5 \\nconcurrent \\nqueries to test \\nsmall user load \\n≤ 3 seconds 2.3 seconds Passed \\nHeavy load (50 \\nusers) \\nYet to be tested \\nLarge dataset \\nretrieval \\nYet to be tested'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 57, 'page_label': '58'}, page_content='5.4.2 Scalability Testing \\n \\nTest Scenario Condition Expected \\nOutcome \\nActual Outcome Result Status \\nIncreasing \\ndataset size \\nNot yet tested \\nIncreasing \\nnumber of \\nconcurrent users \\nNot yet tested \\nHigh-frequency \\nqueries \\nNot yet tested \\n \\n5.4.3 Usability Testing \\n \\nUsability Criteria Evaluation Method Feedback / Outcome Improvements \\nSuggested \\nEase of Use Heuristic evaluation \\n(Nielsen’s heuristics) \\nMost users found the \\ninterface intuitive, \\nespecially for entering \\nqueries and viewing \\nresults. \\nDisplay sample drug \\nqueries (e.g., “What is \\nibuprofen used for?”) \\non the main page for \\nbetter guidance. \\nTask Efficiency User feedback session \\n(5 participants) \\nUsers could retrieve \\nsummarized prompts \\nwithin 2 -3 \\ninteractions. \\nNone suggested. \\nError Prevention Heuristic evaluation The system displayed \\nappropriate warning \\nmessages for empty or \\ninvalid inputs. \\nNo significant \\nimprovements \\nsuggested. \\nOutput Presentation User feedback session Users liked the clear \\npresentation of the \\nfinal prompt and \\nevaluation metrics. \\nSuggestion to display \\nevaluation metrics in a \\ntabular format for \\neasier interpretation. \\nTable 19 Usability Testing'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 58, 'page_label': '59'}, page_content='5.5 Model Testing (for ML Projects) \\n5.5.1 Dataset Testing \\nDatasets Used: \\n1. WebMD Drug Reviews Dataset: The primary dataset containing real-world user reviews \\nof medications and their side effects. \\n2. Synthetic Queries: Custom queries were generated to simulate different user intents and \\nensure robustness under various conditions. \\n \\nTest Scenario Dataset Used Objective Result \\nQuery with clear \\nintent \\nWebMD dataset Validate that the \\nsystem retrieves and \\nsummarizes relevant \\nchunks accurately for \\nqueries with direct \\nintent \\nRetrieved relevant \\nchunks and generated \\na prompt with \\nBERTScore F1 of \\n0.87 and ROUGE -1 \\nscore of 0.55. \\nAmbiguous queries WebMD dataset + \\nsynthetic queries \\nTest system \\nperformance when \\nhandling ambiguous \\nqueries (e.g., \"What is \\nit used for?\"). \\nRetrieved chunks \\ncovered multiple \\ninterpretations of the \\nquery. Prompt \\ngeneration had a \\nBERTScore F1 of \\n0.78. \\nUnseen data Synthetic drug review \\ndata \\nEvaluate the \\nsummarization \\nperformance on \\nunseen reviews. \\nSummarized outputs \\npreserved key content, \\nwith ROUGE -1 of \\n0.58 and ROUGE -L \\nof 0.51. \\nDiverse user queries WebMD + synthetic \\nqueries \\nValidate system \\nperformance for \\nvarying query lengths \\nand contexts. \\nMaintained relevant \\nsummaries with \\nBERTScore Precision \\nof 0.88 across \\ndifferent query types. \\nTable 20 Dataset Testing'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 59, 'page_label': '60'}, page_content='5.6 Edge Case Testing \\nMultiple tests of the RAG Pipeline with prompt compression were conducted to determine its \\nbehavior during unexpected situations and abnormal and extreme conditions. The testing protocol \\nincluded scenarios with empty or nonsensical queries as well as large datasets and hardware failure \\nconditions along with high concurrent usage to verify meaningful system output. \\n \\nTest Case Test Scenario Expected Outcome Actual Outcome \\nEmpty Query User submits an \\nempty query. \\nSystem should display \\na warning message \\nprompting the user to \\nenter a query. \\n \\nMore Testing yet to come. \\n \\n5.7 Limitations of Testing Process \\nOne of the main limitations of the testing process was the hardware constraints, particularly the \\nabsence of high -end GPUs and distributed computing resources. The abstractive summarization \\nmodel (facebook/bart-large-cnn) is computationally intensive, and while it performed \\nwell for small and moderate loads, larger datasets and high -concurrency scenarios led to slightly \\nincreased response times. With access to more powerful hardware, such as dedicated GPUs or \\ncloud-based servers, the performance of the summarization and retrieval processes could be further \\noptimized. \\nAnother challenge involved the dataset size and completeness . While the WebMD Drug \\nReviews dataset provided a robust foundation for testing, the dataset did not cover every possible \\ndrug-related query or medical condition. This limited the scope of testing for highly specific or \\nrare queries. Future work could involve incorporating additional domain-specific datasets, such as \\nclinical trial reports or pharmaceutical databases, to improve the system’s coverage and retrieval \\naccuracy. \\n \\nAdditionally, certain real-world scenarios remained untested. For example, handling adversarial \\ninputs where users intentionally enter conflicting or misleading queries, such as “positive side \\neffects of a drug,” was tested to a limited extent. Expanding the robustness tests to cover \\nadversarial or ambiguous user inputs more comprehensively is a key area for future work.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 60, 'page_label': '61'}, page_content='In future work, these limitations will be addressed by: \\n● Leveraging cloud-based infrastructure: To support high-performance computations and \\nscalability. \\n● Expanding the dataset scope:  Incorporating more comprehensive drug and medical -\\nrelated datasets. \\n● Conducting adversarial and long -duration testing: To ensure system resilience under \\nextreme conditions. \\n● Incorporating human feedback:  To complement quantitative metrics and improve \\noverall system quality. \\n \\n \\n5.9 Chapter Summary \\nThe research presented an extensive validation approach to establish that the RAG Pipeline with \\nprompt compression fulfilled its functional parameters. Functional testing alongside non -\\nfunctional testing and model evaluation together with edge case testing  and testing process \\nlimitations defined the main outcomes and necessary enhancements for future development. \\nFunctional testing verified that primary system elements query processing, chunk retrieval, prompt \\ncompression and user interface through Streamli t operated as designed and fulfilled functional \\nspecifications. The system executed user queries to retrieve appropriate information which it \\ntransformed into usable compressed prompts that remained accurate throughout the process.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 61, 'page_label': '62'}, page_content=\"Chapter 6: Interim Conclusion \\n6.1 Chapter Overview \\nThe implementation and testing stages of RAG Pipeline with prompt compression received \\nevaluation in this chapter for their achievement of original project goals. The current achievements \\nprove substantial advancement in developing an expandable and depend able framework that \\nretrieves and summarizes drug-related information while maintaining user-friendliness. \\n \\n6.2 Achievements of Aims & Objectives \\nThe research objective of this project involves creating and assessing a Retrieval -Augmented \\nGeneration (RAG) pipeline that incorporates prompt compression to effectively retrieve and \\nsummarize drug-related data from extensive datasets. The system connects  FAISS and Sentence-\\nBERT retrieval models and extractive -abstractive summarization models to compact retrieved \\ninformation and retain semantic accuracy alongside contextual relevance. The main goal of this \\nproject involves creating and validating a hybrid compression model which maximizes token \\nefficiency while preserving output quality. \\nThe research target has been successfully met through working implementations of the critical \\nstages starting from data preprocessing to vectorization and retrieval and hybrid compression \\ntechniques and performance evaluations. The system retrieves necessa ry information efficiently \\nbefore using extractive keyword prioritization along with abstractive BART summarization to \\ncompress the data and show token -efficient final prompts. Program effectiveness together with \\nsystem robustness emerges through testing and evaluation results from actual applications. \\n \\n6.3 Challenges and Lessons Learned \\nThe development of the RAG Pipeline with prompt compression  presented several challenges \\nduring the design, implementation, and testing phases. Overcoming these challenges provided \\nvaluable insights that led to key system improvements, optimization strategies, and plans for future \\nenhancements. \\n1. Challenge: Slow Query Retrieval under Large Dataset Loads \\nWhen the dataset exceeded 500K chunks the queries took longer to respond than anticipated which \\nresulted in slower retrieval. Long or complex queries and high concurrency rates both resulted in \\nnoticeable slowness during the system's operation. \\nThe initial design relied on a simple FAISS index configuration with limited optimization. By \\nexperimenting with batching techniques, alternative retrieval distance metrics (Euclidean vs \\ncosine similarity), and partitioned indexing, the system was optimized to handle larger datasets \\nefficiently. Moving forward, integrating distributed FAISS or hierarchical clustering for faster \\nsearches on large datasets could further improve performance.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 62, 'page_label': '63'}, page_content='2. Challenge: Over-Compression of Retrieved Content \\nThe initial summarization process, which prioritized extractive summarization before passing \\nchunks to the abstractive BART summarizer, often resulted in missing critical details due to overly \\naggressive compression. This was reflected in lower -than-expected ROUGE -L scores in some \\ncases (below 0.4 during early tests). \\nThe extractive summarization phase removed essential content when using keyword compression \\nmethods thus causing over compression . The quality of content retention improved when the \\nabstractive summarizer received a larger number of extracted sentences from the testing phase. \\nThe system successfully implemented dynamic sentence retrieval methods which used both query \\nlength and complexity for optimal performance. \\n3. Challenge: Low Retrieval Precision for Ambiguous Queries \\n Ambiguous or vague queries (e.g., \"What is this drug used for?\") led to the retrieval of irrelevant \\nor partially relevant chunks. This affected Recall @ k and user satisfaction, as some queries did \\nnot provide the expected context or relevant information. \\nAmbiguous queries require better handling to improve retrieval precision. The testing process \\nrevealed that expanding queries using synonyms or related terms  (query expansion) can help \\nmatch a wider range of relevant chunks. Incorporating semantic query augmentation based on \\ncontextual embeddings proved useful in initial experiments. \\n4. Challenge: Handling Noisy and Incomplete Queries \\n The system\\'s query encoding performance suffered while retrieving information because noisy \\ninputs with misspellings and typos or incomplete phrases were found to be detrimental. Many \\nqueries were successfully processed by the system yet particular ambigu ous or typo-laden inputs \\npresented challenges for retrieval and summarization processes. \\nPreprocessing user queries using spell-checking, token normalization, and query cleaning  \\nsignificantly improved retrieval performance. Handling noisy inputs effectively involves not only \\ncorrecting errors but also interpreting user intent. \\n5. Challenge: High Latency in Abstractive Summarization \\nThe BART-based abstractive summarization model caused delays when processing large chunks \\nof retrieved content, especially for long queries with many relevant chunks. \\nAbstractive summarization can be optimized by reducing the length of input sequences through \\nmore effective extractive summarization. Additionally, summarization latency can be further \\nimproved by parallelizing summarization tasks or experimenting with faster summarization \\nmodels (e.g., PEGASUS, T5).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 63, 'page_label': '64'}, page_content='6.4 Remaining Work \\nA series of tasks along with improvements have been identified for complete system development \\nwhile preparing the system for deployment. The system development will focus on development \\nmilestones and planned testing phases together with improvements to r etrieval and compression \\nalgorithms and user interface (UI). The identified tasks will boost system scalability as well as \\nimprove performance and user experience. \\nDevelopment Milestones \\n1. Integrate Advanced Query Expansion Techniques \\nImplement semantic query expansion using synonym detection and contextual embeddings to \\nimprove retrieval precision. \\n2. Fine-Tune the Hybrid Compression Model \\nThe BART summarization model requires a specific domain dataset refinement such as clinical \\ntrials or drug reports for better accuracy results. \\n3. Enhance Retrieval Mechanism with Cosine Similarity \\nThe current FAISS index method of Euclidean distance retrieval needs replacement or \\nenhancement with cosine similarity for better chunk relevance. \\n4. Optimize System Performance for High-Concurrency Loads \\nIntroduce caching for frequently queried embeddings and retrieval results to minimize latency \\nduring concurrent user queries.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': 'docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 64, 'page_label': '65'}, page_content=\"Planned Testing Phases \\n1. Adversarial Testing \\nSubmit queries with contradictory or confusing terms to test the system’s ability to handle \\nambiguity. \\n2. Prolonged Stress Testing \\nSimulate continuous user queries over 12 -24 hours to test for memory leaks or performance \\ndegradation. \\n3. Extended Usability Testing \\nConduct sessions where users test the system, providing feedback on the UI and overall \\nexperience. \\n4. Edge Case Testing with Large Data \\nEvaluate the performance and response times when the dataset size is doubled or tripled. \\n \\n \\n \\n6.5 Chapter Summary \\nThe research project's testing process along with its investigation results have been thoroughly \\nexplored in this chapter. This section outlines the testing objectives together with the criteria and \\nfinal results for the main research component and the functional and non-functional requirements \\nof the prototype. The author encountered various restrictions during the testing phase. A \\ncomprehensive discussion regarding the testing challenges encountered by the author has been \\nincluded.\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader('docs/Chenula IPD.pdf')\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './docs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(dir):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(dir + file)\n",
    "        docs = loader.load()\n",
    "        \n",
    "        docs\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=100,\n",
    "#     chunk_overlap=20,\n",
    "#     length_function=len,\n",
    "#     is_separator_regex=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 0, 'page_label': '1'}, page_content='INFORMATICS INSTITUTE OF TECHNOLOGY \\nIn Collaboration with \\nUNIVERSITY OF WESTMINSTER \\n \\nHybrid Prompt Compression for RAG Pipelines \\n \\nA Project Proposal by \\nChenula Senkith Jayasinghe \\n \\nSupervised by \\nMr Vinula Uthsara Buthgamumudalige \\n \\n \\n \\n \\n \\n \\n02/2025'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 1, 'page_label': '2'}, page_content='Abstract  \\n \\nWith the huge growth of unstructured textual data in the healthcare domain, retrieval and \\nsummarization of relevant information is a critical problem for healthcare professionals and \\nresearchers. We propose a Retrieval -Augmented Generation (RAG) pipeline f or prompt \\ncompression to minimize tokens while achieving a high response accuracy. It combines dense \\nvector-based retrieval using FAISS with two stage compression: an extractive stage to identify the \\nkeys sentences and an abstractive stage to compress the extracted information. \\nThe user’s query is combined with the compressed content for the large language models (LLMs) \\nsuch as GPT -3 or ChatGPT, creating an optimized prompt for an effective and cost -efficient \\nresponse. For query encoding, the project utilizes Sentence-BERT, for abstractive compression it \\nuses BART, and for user interaction it utilizes Streamlit interface. Finally, the system is evaluated'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 1, 'page_label': '2'}, page_content='using metrics including compression ratio and token savings, ROUGE scores and response \\naccuracy. This project seeks to provide a practical and scalable solution to the problem of querying \\nlarge medical datasets with low token consumption in LLM based applications.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 2, 'page_label': '3'}, page_content='Table of Contents \\n  \\nTable of Contents ................................ ................................ ................................ ............. 3 \\nList of Tables ................................ ................................ ................................ ................... 5 \\nList of Figures ................................ ................................ ................................ .................. 6 \\nChapter 1: Introduction ................................ ................................ ................................ ....... 7 \\n1.1 Chapter Overview ................................ ................................ ................................ ....... 7 \\n1.2 Problem Identification ................................ ................................ ................................  7 \\n1.3 Problem Background / Problem Domain ................................ ................................ ...... 8'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 2, 'page_label': '3'}, page_content='1.4 Problem Definition ................................ ................................ ................................ .....10 \\n1.5 Research Gap ................................ ................................ ................................ ............11 \\n1.6 Contribution to the Body of Knowledge ................................ ................................ ......14 \\n1.7 Research Aim ................................ ................................ ................................ ............17 \\n1.8 Research Objectives ................................ ................................ ................................ ...17 \\n1.9 Novelty ................................ ................................ ................................ ......................19 \\n1.10 Chapter Summary................................ ................................ ................................ ....21'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 2, 'page_label': '3'}, page_content='Chapter 2: Requirements Specification ................................ ................................ ................22 \\n2.1 Chapter Overview ................................ ................................ ................................ ......22 \\n2.2 Rich Picture Diagram ................................ ................................ ................................ 22 \\n2.3 Stakeholder Analysis ................................ ................................ ................................ ..23 \\n2.4 Requirement Elicitation Methodologies ................................ ................................ ......23 \\n2.5 Findings from Elicitation ................................ ................................ ............................24 \\n2.6 Context Diagram ................................ ................................ ................................ .......27'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 2, 'page_label': '3'}, page_content='2.7 Use Case Diagram and Descriptions................................ ................................ ............27 \\n2.8 Functional and Non-Functional Requirements ................................ ............................28 \\n2.9 Chapter Summary ................................ ................................ ................................ .....30 \\nChapter 3: Design ................................ ................................ ................................ ...............31 \\n3.1 Chapter Overview ................................ ................................ ................................ ......31 \\n3.3 System Architecture Design ................................ ................................ ........................32 \\n3.4 Detailed Design ................................ ................................ ................................ ..........35'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 2, 'page_label': '3'}, page_content='3.5 Algorithm Design ................................ ................................ ................................ .......35 \\n3.6 UI Design Wireframe ................................ ................................ ................................ .37 \\n3.7 Chapter Summary ................................ ................................ ................................ .....38'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 3, 'page_label': '4'}, page_content='Chapter 4: Implementation ................................ ................................ ................................ .39 \\n4.1 Chapter Overview ................................ ................................ ................................ ......39 \\n4.2 Technology Selection ................................ ................................ ................................ ..39 \\n4.3 Core Functionalities Implementation ................................ ................................ ..........43 \\n4.4 User Interface Implementation ................................ ................................ ...................46 \\n4.5 Challenges and Solutions ................................ ................................ ............................50 \\n4.6 Chapter Summary ................................ ................................ ................................ .....51'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 3, 'page_label': '4'}, page_content='Chapter 5: Testing ................................ ................................ ................................ ..............52 \\n5.1 Chapter Overview ................................ ................................ ................................ ......52 \\n5.2 Testing Criteria ................................ ................................ ................................ .........52 \\n5.3 Functional Testing ................................ ................................ ................................ .....55 \\n5.4 Non-Functional Testing ................................ ................................ .............................. 57 \\n5.5 Model Testing (for ML Projects) ................................ ................................ ................59 \\n5.6 Edge Case Testing ................................ ................................ ................................ ......60'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 3, 'page_label': '4'}, page_content='5.7 Limitations of Testing Process ................................ ................................ ....................60 \\n5.9 Chapter Summary ................................ ................................ ................................ .....61 \\nChapter 6: Interim Conclusion ................................ ................................ ............................62 \\n6.1 Chapter Overview ................................ ................................ ................................ ......62 \\n6.2 Achievements of Aims & Objectives................................ ................................ ............62 \\n6.3 Challenges and Lessons Learned ................................ ................................ ................62 \\n6.4 Remaining Work ................................ ................................ ................................ .......64'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 3, 'page_label': '4'}, page_content='6.5 Chapter Summary ................................ ................................ ................................ .....65'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 4, 'page_label': '5'}, page_content='List of Tables \\n \\nTable 1 Summary of Research Gap ................................ ................................ ..........................14 \\nTable 2 Research Objectives ................................ ................................ ................................ ....19 \\nTable 3 Requirement Elicitation Methodologies ................................ ................................ .........24 \\nTable 4 Litreature Review ................................ ................................ ................................ .........25 \\nTable 5 Interviews ................................ ................................ ................................ .....................26 \\nTable 6 Functional Requirements................................ ................................ .............................. 29 \\nTable 7 Non - Functional Requirements ................................ ................................ ....................30'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 4, 'page_label': '5'}, page_content='Table 8 Design Goals................................ ................................ ................................ ................32 \\nTable 9 Technology Stack ................................ ................................ ................................ .........40 \\nTable 10 Dataset Selection ................................ ................................ ................................ .......41 \\nTable 11 Programming Languages ................................ ................................ ...........................42 \\nTable 12 Library Toolkit ................................ ................................ ................................ .............43 \\nTable 13 Core Functionality Implementation ................................ ................................ .............44 \\nTable 14 UI Elements................................ ................................ ................................ ................47'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 4, 'page_label': '5'}, page_content='Table 15 Challengers and Solutions ................................ ................................ ..........................51 \\nTable 16 Non-Functional Requirements ................................ ................................ ....................53 \\nTable 17 Model Performance Metrics ................................ ................................ ........................54 \\nTable 18 Functional Testing ................................ ................................ ................................ ......57 \\nTable 19 Usability Testing ................................ ................................ ................................ .........58 \\nTable 20 Dataset Testing ................................ ................................ ................................ ..........59'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 5, 'page_label': '6'}, page_content='List of Figures \\n \\nFigure 1 Rich Picture Diagram ................................ ................................ ................................ ..23 \\nFigure 2 Context Diagram ................................ ................................ ................................ .........27 \\nFigure 3 Architecture Diagram ................................ ................................ ................................ ..33 \\nFigure 4 Query Embedding ................................ ................................ ................................ .......36 \\nFigure 5 Hybrid Compression ................................ ................................ ................................ ....36 \\nFigure 6 Prompt Generation ................................ ................................ ................................ ......37 \\nFigure 7 UI Wireframe ................................ ................................ ................................ ...............37'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 5, 'page_label': '6'}, page_content='Figure 8 User Interface ................................ ................................ ................................ .............49'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 6, 'page_label': '7'}, page_content='Chapter 1: Introduction \\n1.1 Chapter Overview \\nThe purpose of this chapter is to give an initial view of the problem domain and the need of \\nresolving the main challenges in retrieving and compressing unstructured medical data. It lays the \\nfoundation for the research objectives, methodology and the enti re project structure. This chapter \\njustifies that existing systems have limitations, and thus a Retrieval-Augmented Generation (RAG) \\npipeline that combines dense retrieval and prompt compression is needed to solve the problem \\nidentified. \\nThe chapter connects the problem domain to the following chapters by explaining the issues of \\nworking with large amounts of unstructured data in healthcare domain and making input suitable \\nfor big language models (LLMs). Current methods either generate sem antically meaningful \\nretrieval or generate summaries that are too long to be efficiently processed by LLMs. Thus, the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 6, 'page_label': '7'}, page_content='retrieval or generate summaries that are too long to be efficiently processed by LLMs. Thus, the \\nroot causes and gaps in current systems need to be understood to help develop a good solution. \\nAdditionally, this chapter also introduces the research gap and the proposed approach by providing \\na combination of dense retrieval using FAISS and extractive abstractive compression to address \\nthe limitations of traditional retrieval and summarization met hods. This chapter lays out the \\nobjectives and contributions of the project by setting the scene for the system design, \\nimplementation, and evaluation of the remaining chapters. \\n \\n \\n1.2 Problem Identification \\nThis section is to define the real world problem this project wants to solve, both in technical and \\npractical terms. It focuses on the importance of the problem within the domain of healthcare \\ninformatics, more specifically, the efficient retrieval and com pression of large scale drug review'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 6, 'page_label': '7'}, page_content='data for large language models (LLMs). \\nThere are large collections of user generated content (reviews, feedback and experiences) for \\nvarious medications in health care platforms like WebMD and UCI ML Drug Reviews. In these \\nreviews, drug effectiveness, side effects, dosage experiences are descri bed with the help of \\ndifferent patients and healthcare professionals. Although this data has good information, it is \\nunstructured, repetitive and redundant, so it is difficult to retrieve and summarize relevant \\ninformation quickly.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 7, 'page_label': '8'}, page_content='The problem is, as follows: \\n1. Large Volume of Data: \\nThe reviews are usually in thousands, and a user cannot process them manually. \\n2. Scattered and Redundant Information: \\nScattered across multiple reviews and merged with repetitions, important details such as side \\neffects, dosage recommendations and treatment outcomes are mixed. But to search for concise and \\naccurate information is difficult. \\n3. Complexity of Summarization: \\nThere are challenges in generating summaries from long texts from user generated content, which \\nvary in writing styles, formats and may contain irrelevant information. \\n4. LLM Token Constraints: \\nWhen interfacing with LLMs like GPT3 or ChatGPT, you have to deal with tokens limitations \\nsince such models have a fixed number of tokens per request (e.g., GPT3 has a maximum of 4,096 \\ntokens per request). For example, if a query produces too many uncompre ssed chunks, the LLM \\nmay produce half or incomplete answers. \\n \\n \\n1.3 Problem Background / Problem Domain'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 7, 'page_label': '8'}, page_content='may produce half or incomplete answers. \\n \\n \\n1.3 Problem Background / Problem Domain \\nDigital data production in the healthcare industry has experienced a rapid growth due to \\ninnovations in online health platforms, electronic health records (EHRs), and patient generated \\ncontent. WebMD, Drugs.com, and UCI ML Drug Reviews are platforms with user feedback about \\nmedications such as reports of side effects, dosage effectiveness and patient experiences. \\nNevertheless, the data in this study is unstructured and textual in nature, which makes efficient \\nretrieval and processing difficult.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 8, 'page_label': '9'}, page_content='Trends Shaping the Problem Domain \\n1. Growth of User-Generated Content: \\nAs medical advice and patient reviews are increasingly sought out online, there are huge \\nunstructured datasets being amassed. Because patients often have subjective and diverse \\nexperiences with medications, they have variability in how they write, what they write, and \\nin the structure of the reviews. \\nConstraints: Drug effectiveness and side effect expressions are diverse and should be \\nunderstood by a retrieval system. \\n2. Adoption of Large Language Models (LLMs): \\nApplications of such advances in Natural Language Processing (NLP), including GPT -3, \\nBERT and ChatGPT, include automated response generation, clinical decision support and \\npersonalized recommendations. Nonetheless, these models are limited by token limits and \\nefficient input prompt construction is essential for real world use. \\nOptimization: In order to interact with LLMs cost effectively, we need to optimize token'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 8, 'page_label': '9'}, page_content='Optimization: In order to interact with LLMs cost effectively, we need to optimize token \\nusage via prompt compression. \\n3. Emphasis on Evidence-Based Medicine: \\nThere is an increasing focus on data-driven, evidence-based decision-making in healthcare. \\nMedical professionals rely on aggregated insights from multiple patient experiences and \\nclinical outcomes to make informed decisions. However, the manual aggregation  of \\nscattered and redundant information from large datasets is time -consuming and prone to \\nhuman error. \\nImplication: Automated systems for retrieving and summarizing key information are \\nessential to support evidence-based decision-making. \\n4. LLM-Compatible Prompt Construction \\nThe final compressed prompt must contain sufficient context and information to allow the \\nLLM to generate relevant, accurate, and factually correct responses to the user query. \\nPoorly structured or excessively compressed prompts may lead to hallucinations o r'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 8, 'page_label': '9'}, page_content='Poorly structured or excessively compressed prompts may lead to hallucinations o r \\ninaccurate outputs from the LLM. The challenge is to optimize token savings without \\nsacrificing the completeness and correctness of the generated response.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 9, 'page_label': '10'}, page_content='1.4 Problem Definition \\nProblem Statement \\n“ How can we efficiently retrieve and compress large-scale, unstructured drug review data to \\nconstruct token-optimized prompts for large language models (LLMs) while maintaining \\naccuracy, contextual relevance, and minimal token usage? ” \\nTechnical and Operational Aspects of the Problem \\n1. Efficient Information Retrieval \\nMany large medical datasets like WebMD Drug Reviews contain thousands of user \\ngenerated reviews for drugs with descriptions of how effective it is, what side effects it \\ncreates, and patient experience. The problem is how we can retrieve only the most relevant \\nknowledge chunks which correspond to a user query while retrieving the knowledge \\nchunks in a way that the knowledge retrieval system understands semantic meaning, not a \\nsimple keyword match. \\nOperational Challenge: Traditional retrieval systems based on keyword search methods \\nare not good at understanding complex natural language queries and frequently produce'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 9, 'page_label': '10'}, page_content='are not good at understanding complex natural language queries and frequently produce \\nirrelevant or incomplete results. Thus, it needs a dense vector based retrieval system (using \\nFAISS) to achieve high retrieval accuracy. \\n2. Compression of Retrieved Information \\nAfter that, they have to compress the relevant reviews into a small token footprint to pass \\nas a prompt to large language models. Since LLMs like GPT-3 have strict token limitations \\n(i.e., 4,096 tokens per request for GPT -3), they cannot process long, unco mpressed \\ndocuments directly. The prompt construction may exclude or truncate critical details \\nwithout compression. \\nTechnical Challenge : The compression must be able to strike a balance between \\ndecreasing token count and maintaining important information. Truncation or extractive \\nsummarization may not capture nuances and context. Thus, a two stage compression \\nmethod is required.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 9, 'page_label': '10'}, page_content='method is required. \\nStage 1 (Extractive Compression): Extractive compression, that is, identify key sentences \\ndirectly from the retrieved reviews.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 10, 'page_label': '11'}, page_content='Stage 2  (Abstractive Compression): Compress and rephrase the extracted sentences to \\nmake them coherent, and to be token efficient. \\n3. LLM-Compatible Prompt Construction \\nThe compressed prompt has to have enough context and information for LLM to generate \\nrelevant, accurate, and factually correct response to the user query. If prompts are badly \\nstructured or too compact, then this can cause hallucinations or incorrect outpu ts by the \\nLLM. The difficulty is to achieve token savings optimality while keeping the generated \\nresponse as complete and correct as possible. \\n \\n \\n1.5 Research Gap \\n \\n1.5.1 Overview of Existing Solutions \\nThere are numerous studies and systems which focused on information retrieval, summarization, \\nand processing very large text datasets using large language models (LLMs). Traditional \\napproaches include: \\n1. Information Retrieval Systems: \\nThe commonly used ways of retrieving relevant documents based on user queries are by'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 10, 'page_label': '11'}, page_content='The commonly used ways of retrieving relevant documents based on user queries are by \\nkeyword based search engines and by TF-IDF based retrieval systems. \\nFor dense vector based retrieval systems, like those using BERT embeddings or FAISS, \\nretrieving using semantic meaning has been shown to improve performance over exact \\nkeyword matches. \\n2. Summarization Techniques: \\nExtractive summarization: Selects the most important sentences from the text verbatim. \\nBoth models such as BERTSUM and Sumy fall in this category. \\nAbstractive Summarization: Generating concise, human -like summaries that rephrase the \\nkey information are referred to as abstractive summarization. BART and PEGASUS are \\npopular abstractive models. \\n3. Prompt Construction for LLMs: \\nThe current system finds user queries and give them to LLMs, or reduce the token count \\nof the input by means of generic summarization.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 11, 'page_label': '12'}, page_content='1.5.2 Deficiencies in Existing Systems and Knowledge \\nDespite advancements in retrieval, summarization, and LLM -based applications, several \\nunresolved issues remain: \\n1. Inefficient Retrieval Mechanisms: \\nRetrieval systems based on keywords fail to provide semantic meaning of user query. For \\nexample: “What are the side effects of ibuprofen?” If they don’t explicitly match the query \\nterms, may not retrieve documents that mention related terms such as “dizzin ess”, or \\n“nausea”. \\nDespite the density of the retrieval systems utilized, existing methods tend to design their \\nretrieval towards query -document full document retrieval rather than relevant document \\nchunks within that document, resulting in large and redundant retrieved outputs. \\n2. Lack of Token Optimization in Summarization: \\nTypically, summarization systems aim to produce human readable summaries and optimize \\nfor efficiency of tokens when interacting with models such as GPT -3 or ChatGPT, which'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 11, 'page_label': '12'}, page_content='for efficiency of tokens when interacting with models such as GPT -3 or ChatGPT, which \\nare limited in terms of the number of tokens they can work with. \\nExtractive only systems choose redundant and verbose sentences and Abstractive only \\nsystems can lose very important details because of oversimplification. A key gap is that \\ncurrent systems do not have a hybrid (extractive + abstractive) approach. \\n3. Balancing Compression and Accuracy: \\nIn the case of complex, multi -faceted information like drug side effects and dosage \\nrecommendations, the loss of critical detail can occur even with excessive compression. \\nIn contrast, minimal compression causes token overload and hence yields incomplete or \\ntruncated responses from LLMs. There are not effective strategies in current literature to \\nbalance compression ratio and output accuracy. \\n4. Limited Integration with LLMs for Real-Time Use: \\nSimilar to LLMs, LLMs have already been successfully used for general purpose question'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 11, 'page_label': '12'}, page_content='Similar to LLMs, LLMs have already been successfully used for general purpose question \\nanswer and text generation but existing systems still do not provide real time integration \\nwhere user queries are taken in automatically, compressed and structured into prompts for \\nimmediate processing by LLMs. \\nAlso, user end interfaces (e.g., healthcare professionals) are not well explored.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 12, 'page_label': '13'}, page_content='1.5.3 Why Addressing This Gap Is Necessary \\n1. Practical Need for Efficient Information Retrieval in Healthcare: \\nTimely access to accurate and concise drug related information can help in making \\ndecisions both for medical professionals as well as patients in the healthcare domain. \\nHowever, current systems are inefficient and prone to errors as users need to manually go \\nthrough several reviews. \\nTo address this gap, we develop a dense retrieval and prompt compression pipeline that \\nenables users to get to actionable knowledge in real time. \\n2. Cost-Effectiveness in Using LLMs: \\nGPT-3 is a large language model and it has token based pricing model. In the absence of \\nthe proper token optimization, queries may pay high costs or get truncated results from the \\ntoken limit. \\nThe project closes that gap by compressing prompts without losing key info so the costs \\nare reduced and the LLM capabilities are used effectively. \\n3. Scalable and Flexible Solutions:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 12, 'page_label': '13'}, page_content='are reduced and the LLM capabilities are used effectively. \\n3. Scalable and Flexible Solutions: \\nWith the increase in volume of user generated medical content, the system must be scalable \\nfor large datasets with minimal performance loss. \\nThis project is scalable and generalizable to other domains such as legal documents, \\nfinancial reports, scientific papers by integrating dense retrieval and hybrid compression. \\n \\n1.5.4 Summary of the Research Gap \\n \\nAspect Existing Limitation Proposed Solution \\nRetrieval Efficiency Keyword-based and \\ndocument-level retrieval fail \\nto return contextually relevant \\nchunks \\nUse dense vector-based \\nretrieval via FAISS and \\nBERT \\nToken Optimization Existing summarization \\nfocuses on human readability, \\nnot token savings \\nImplement a two-stage \\ncompression pipeline \\n(extractive + abstractive) \\nCompression-Accuracy Excessive compression leads Optimize compression by'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 13, 'page_label': '14'}, page_content='Tradeoff to loss of details, minimal \\ncompression leads to token \\noverload \\nbalancing token savings and \\noutput accuracy \\nReal-Time User Interaction Limited integration with \\ninteractive LLM-based \\nsystems \\nDevelop a real-time User \\ninterface for query \\nprocessing \\nTable 1 Summary of Research Gap \\n \\n1.6 Contribution to the Body of Knowledge \\n1.6.1 Theoretical Contributions \\n1. Integration of Prompt Compression into RAG Pipelines: \\nThe main contribution of this work is to seamlessly integrate prompt compression into the \\nRAG pipeline, which is centered around retrieval and general purpose summarization. This \\nintegration makes the pipeline a token optimized, LLM ready system by: \\n● A two stage compression process – first, an extractive stage to extract the best \\nsentences from given chunks as answers to the query, and second, an abstractive \\nstage to compress and refine the extracted information. \\n● Making token optimization a central component to embed, while maintaining the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 13, 'page_label': '14'}, page_content='● Making token optimization a central component to embed, while maintaining the \\naccuracy of LLM prompts and keeping them under token limits. \\nApplications: This contribution advances beyond the state of the art in RAG research by \\noptimizing the pipeline for relevance (via retrieval) as well as token efficiency to be \\nsuitable for cost sensitive applications involving LLMs. \\n2. Token-Efficient Prompt Construction: \\nThe project presents a new methodology to balance between compression and accuracy using \\nmultiple evaluation metrics such as compression ratio, token savings, and BERTScore accuracy. \\nBy doing so, this contribution ensures that the compressed prompt. \\n● Keeps the key information necessary for the accurate responses. \\n● Reduces redundancy of and irrelevance to the content so that tokens are used as little as \\npossible. \\nUnlike traditional summarization systems that typically come up with long length outputs, this'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 13, 'page_label': '14'}, page_content='Unlike traditional summarization systems that typically come up with long length outputs, this \\nproject presents a compression framework tailor made for LLM constraints for advancement.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 14, 'page_label': '15'}, page_content='3. Enhanced Retrieval through Dense Vector Representations: \\nThis project helps with advancements in retrieval techniques by using FAISS (Facebook \\nAI Similarity Search) and Sentence -BERT to retrieve semantically relevant chunks of \\ninformation from the database using user queries. \\n● With smaller, contextually meaningful portions of text known as retrieved chunks, \\nthey are more efficient to process downstream and compress than complete \\ndocuments. \\nPrecision: This project increases the precision of retrieval by focusing on retrieving \\ncontextually relevant chunks, and consequently, less information needs to be compressed. \\n4. Evaluation Framework for Prompt Compression in RAG Pipelines: \\nA multi metric evaluation framework for the performance of the prompt compression \\nprocess is developed in the project. The framework evaluates: \\n● Measuring the efficiency with which the information is compressed, i.e. token \\nsavings.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 14, 'page_label': '15'}, page_content='● Measuring the efficiency with which the information is compressed, i.e. token \\nsavings. \\n● Comparison of the original text size vs. the final compressed prompt. \\n● BERTScore/ROUGE scores: Maintaining the meaning of the compressed output. \\nApplication: The framework also enables future researchers to identify the appropriate \\nbalance between token efficiency and response quality in RAG systems. \\n \\n1.6.2 Practical Contributions \\n1. Efficient Token-Optimized LLM Prompts for Real-World Use: \\nIncorporating prompt compression to the RAG pipeline, the system creates \\ncompact prompts, limited to the minimum tokens to maintain the prompt \\nintelligibility and provide enough context for correct LLM responses without using \\nmore than necessary. As a resu lt, the cost is reduced and query efficiency is \\nimproved when querying large language models like GPT-3 or ChatGPT. \\n2. Scalable Integration of RAG Pipelines in Various Domains:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 14, 'page_label': '15'}, page_content='2. Scalable Integration of RAG Pipelines in Various Domains: \\nThe architecture of the system is scalable and adjustable so it can be applied to more \\nthan just the health care industry. This provides a way of efficiently compressing \\nlarge scale textual datasets such as:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 15, 'page_label': '16'}, page_content='Legal documents: Compressing case summaries. \\nFinancial reports: Summarizing key financial metrics and performance indicators. \\nScientific reports: Extracting and compressing key finds and conclusions from \\nscientific research papers. \\nApplication areas: This generalizable system can be directly applied to any industry \\nneeding concise, accurate summaries for decision making. \\n3. User-Friendly Interface for Querying and Compression: \\nThe project offers an interactive Streamlit interface to users for submitting queries \\nand receiving compressed, token efficient responses in real time. It is a practical \\nand easy to use solution that can be interacted with by users without technical \\nbackground. \\nBenefits: The interface fills the gap between technical NLP models and non-expert \\nusers by offering a simple query response mechanism. \\n4. Cost-Effective Use of LLMs: \\nFor LLMs based on tokens, by reducing the number of tokens of inputs, the system'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 15, 'page_label': '16'}, page_content='For LLMs based on tokens, by reducing the number of tokens of inputs, the system \\nsaves costs when interacting with token based LLMs such as GPT -3. Low cost of \\noperation is a benefit to both large enterprises and small organizations alike, while \\ncontinuing to provide access to high quality, AI driven responses. \\nToken overload:  Organizations can avoid spending prohibitively high costs on \\ntoken overload when scaling the use of LLMs.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 16, 'page_label': '17'}, page_content='1.7 Research Aim \\nThe goal of this work is to build a Retrieval Augmented Generation (RAG) pipeline to retrieve, \\ncompress and optimize unstructured large scale drug review data for interaction with large \\nlanguage models (LLMs) using dense retrieval and prompt compression. \\nThe project seeks to achieve: \\n● Dense vector based methods to efficiently retrieve relevant information using dense vectors \\nto make semantically accurate matches for user queries. \\n● Two stage approach (extractive and abstractive compression) of token efficient \\ncompression of retrieved content without compromising accuracy or key information. \\n● User friendly interface, real time interaction with concise and actionable responses for the \\npatients and healthcare professionals. \\nTherefore, the research will enable meeting this goal, which will tackle key challenges of working \\nwith large scale textual data, minimizing token overhead, and performing cost effective and'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 16, 'page_label': '17'}, page_content='with large scale textual data, minimizing token overhead, and performing cost effective and \\naccurate querying of LLMs such as GPT-3 or ChatGPT. \\n \\n \\n1.8 Research Objectives \\n \\n \\nObjective  Description Learning Outcomes \\nLiterature Survey - To explore current \\nadvancements in Retrieval-\\nAugmented Generation \\n(RAG) pipelines and identify \\ngaps in existing systems. \\n \\n- To analyze compression \\ntechniques (both extractive \\nand abstractive) and their \\napplications in token -efficient \\nNLP systems. \\n \\n- To review previous research \\non dense retrieval (FAISS)  \\nand its integration with \\nsummarization systems. \\n- To select the appropriate \\nLO1, LO2, LO4'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 17, 'page_label': '18'}, page_content='retrieval models, \\ncompression techniques, and \\nevaluation metrics  for the \\nproject. \\nRequirement Analysis - To gather requirements from \\nhealthcare professionals, \\nresearchers, and technical \\nusers regarding the retrieval \\nand summarization of large \\nmedical datasets. \\n \\n- To define functional and \\nnon-functional requirements \\nrelated to retrieval speed, \\ntoken savings, and accuracy. \\nLO3, LO6 \\nDesign - To design the architecture for \\na dense retrieval and prompt \\ncompression pipeline , \\nintegrating FAISS-based \\nretrieval and a two -stage \\ncompression module. \\n \\n- To define the flow of \\ninformation from user query \\ninput to LLM -optimized \\nprompt generation. \\n \\n- To design evaluation metrics \\nfor assessing the performance \\nof token savings, \\ncompression ratio, and \\naccuracy. \\nLO3, LO5 \\nDevelopment -To implement the dense \\nretrieval system using FAISS \\nand Sentence-BERT to return \\nsemantically relevant chunks. \\n \\n- To develop and integrate the \\ntwo-stage compression'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 17, 'page_label': '18'}, page_content='semantically relevant chunks. \\n \\n- To develop and integrate the \\ntwo-stage compression \\nmodule (extractive + \\nabstractive) using BERT and \\nBART models. \\nLO7'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 18, 'page_label': '19'}, page_content='Testing - To create test plans for \\nevaluating the system’s \\nperformance based on \\ncompression ratio, token \\nsavings, retrieval accuracy, \\nand response time. \\n \\n- To conduct unit testing for \\nindividual components \\n(retrieval, compression) and \\nintegration testing for the \\noverall pipeline. \\nLO8 \\nEvaluation - To evaluate the system using \\nBERTScore, ROUGE, \\ncompression ratio, and \\nperplexity metrics. \\n \\n- To demonstrate the \\ndeveloped system to domain \\nexperts and gather feedback \\nthrough a demo session or viva \\npanel. \\nLO9 \\nTable 2 Research Objectives \\n \\n1.9 Novelty \\n1.9.1 Novelty of the Problem \\nThe problem addressed by this project is not merely retrieval or summarization but involves the \\noptimization of prompts for large language models (LLMs) through efficient compression. This \\nproblem is unique because: \\n● Traditional RAG systems primarily focus on retrieving and summarizing information \\nwithout explicitly optimizing token usage for LLMs like GPT-3 or ChatGPT.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 18, 'page_label': '19'}, page_content='without explicitly optimizing token usage for LLMs like GPT-3 or ChatGPT. \\n● The challenge lies in balancing information retention and token reduction within the \\nconstraints of token -based models. This problem requires a novel approach to select, \\ncompress, and rephrase information while retaining its semantic integrity. \\nBy defining the problem in terms of prompt optimization for token efficiency , this project \\naddresses a key gap in existing research where token savings and cost reduction have been \\nunderexplored in LLM-based applications.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 19, 'page_label': '20'}, page_content='1.9.2 Novelty of the Solution \\nThe solution presented by this project is novel in its hybrid design that integrates dense retrieval \\nwith two-stage prompt compression. Key innovative aspects include: \\n1. Seamless Integration of Retrieval and Compression: \\n○ The project goes beyond conventional retrieval systems by integrating dense \\nretrieval using FAISS with two-stage prompt compression. \\n○ This integration enables the system to retrieve semantically relevant chunks and \\ncompress them into token -efficient prompts, making it a unique solution for real -\\ntime LLM interactions. \\n2. Two-Stage Compression Pipeline: \\n○ The system combines extractive compression (using BERT) to select key sentences \\nand abstractive compression (using BART) to refine and further compress the \\nselected content. \\n○ Unlike traditional summarization techniques, which either extract or paraphrase \\ninformation, this hybrid approach ensures both token efficiency and semantic \\ncompleteness.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 19, 'page_label': '20'}, page_content='information, this hybrid approach ensures both token efficiency and semantic \\ncompleteness. \\n3. Token Optimization as a Central Goal: \\n○ Most summarization techniques generate human -readable summaries but do not \\nexplicitly optimize for token constraints imposed by LLMs. \\n○ This project introduces token savings and compression ratio as key performance \\nmetrics, ensuring that the final output is both concise and informative. \\n \\n  \\n \\n \\n \\n \\n1.9.3 Novelty of the Methodology \\n1. Application of Dense Vector Retrieval (FAISS) to Generate Compressed Prompts:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 20, 'page_label': '21'}, page_content='● The project applies FAISS-based dense retrieval not just to retrieve full documents but to \\nextract contextually relevant knowledge chunks that serve as input to the compression \\npipeline. \\n● This methodology ensures that the retrieved content is already relevant and focused, \\nreducing the need for excessive filtering and summarization. \\n2. Multi-Metric Evaluation of Compression: \\n● The project employs a comprehensive evaluation framework  combining multiple \\nmetrics, including: \\n○ Compression ratio: To measure the reduction in token count. \\n○ ROUGE and BERTScore: To ensure semantic and contextual accuracy. \\n○ Perplexity: To measure the fluency of the compressed prompt. \\n● This multi-metric approach is novel in the context of RAG pipelines and can be adopted as \\na best practice for future systems involving prompt construction and optimization. \\n \\n \\n \\n \\n \\n \\n1.10 Chapter Summary \\nThis chapter introduced the core problem of efficiently retrieving and compressing large -scale,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 20, 'page_label': '21'}, page_content='This chapter introduced the core problem of efficiently retrieving and compressing large -scale, \\nunstructured drug review data for token-optimized interactions with large language models \\n(LLMs). The project aims to address the limitations of current retrieval and summarization \\nsystems by integrating prompt compression into a Retrieval-Augmented Generation (RAG) \\npipeline. \\nThe problem arises from the inefficiency of manually processing large datasets and the token \\nconstraints of LLMs  like GPT-3, which require optimized inputs to deliver cost -effective and \\naccurate responses. The research gap identified in this chapter highlights the lack of systems that \\nsimultaneously address retrieval efficiency and token savings through compression.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 21, 'page_label': '22'}, page_content='Chapter 2: Requirements Specification \\n2.1 Chapter Overview \\nThe present chapter deals with the elaboration of the overall requirement gathering process for the \\ngiven research project, from the very core of research to prototype development. To start off, the \\nidentification and diagramming of stakeholders in the pro posed system, their roles, and their \\nrelations with the help of graphs is performed. After which discussion and analysis of the various \\nrequirement elicitation techniques which may be used, by selecting in detail, is presented. The \\nelicited requirements ar e then represented in tabular format, use case diagrams along with their \\ndescriptions are developed. Finally, the conclusions drawn from the requirement elicitation process \\nare interpreted and summarized. \\n \\n2.2 Rich Picture Diagram \\n \\nThe objective of a rich picture diagram is to be able to illustrate the relationships which would exist'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 21, 'page_label': '22'}, page_content=\"between the proposed system and its wider environment. These entities may extend beyond the \\ntertiary relationships to the system's own domain. Also, thi s rich picture diagram Also \\ndemonstrates potential threats and vulnerabilities that may affect the proposed system due to \\nactivities of malicious actors and lawful competitors alike.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 22, 'page_label': '23'}, page_content='Figure 1 Rich Picture Diagram \\n \\n \\n2.3 Stakeholder Analysis \\n \\n \\n2.4 Requirement Elicitation Methodologies \\nRequirement Elicitation is a critical step of software development which is all about acquiring the \\nrequirements for a software project who enables the developers gain a bird’s eye view of \\nappreciation of what it is, what it seeks: to achieve, its mission and vision. The tables below are a \\nbrief profile of the selected requirement elicitation methods and rationale with a focus on the \\nmerits/benefits of each certain procedure and cons. \\n \\nTechnique 1 – Interviews \\nSome interviews were useful in establishing the current state of the issues affecting efficiency'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 23, 'page_label': '24'}, page_content='in handling LLM’s and prompt processing. The importance of the parameters for quantifying \\nsuch as accuracy, response time, and token usage and domain experts assisted in the \\nidentification of possibilities for compression.  \\nTechnique 2 - Literature Review \\nThe Literature Review offered insights into the deficiencies on current LLM solutions and \\nprovided points at which timely compression would be of value over the efficiency of the \\nmodel. By reviewing the documentation of models such as GPT-3, LLama2 and BERT it was \\neasier to pinpoint areas where compression techniques could be integrated. \\nTechnique 3 - Brainstorming Sessions \\nThe concept generation helped in group thinking and was useful in coming up with a novel \\nplan of managing token issues and handlings such as maintaining essential context \\ninformation. This method fostered innovativeness and was also such that enabled successive \\nprototyping of concepts. \\nTable 3 Requirement Elicitation Methodologies'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 23, 'page_label': '24'}, page_content='prototyping of concepts. \\nTable 3 Requirement Elicitation Methodologies \\n \\n \\n \\n \\n \\n2.5 Findings from Elicitation \\n2.5.1 Literature Review \\n \\nCitation Findings  \\nBrown et al., 2020; Devlin et al., 2019  Prior large language models (LLMs), including \\nGPT-3 and BERT, face some difficulty in \\naddressing the problems involving long inputs, \\nand the trade -offs between speed and \\ncapability. The majority of existing models is \\ndesigned to provide the most accurate a nd \\nrelevant output, but there is a number of \\ndrawbacks when using it with large inputs.  \\nSanh et al., 2019; Jiao et al., 2020  Experiments in the area of NLP’s timely \\ncompression revealed that it is important to \\npreserve the context to relevant and coherent \\nresults. Although to increase the speed of the \\nprocess such a reduction of tokens as pruning'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 24, 'page_label': '25'}, page_content='or distillation often causes the loss of highly \\nimportant contextual information which \\nfurther influences the relevance and accuracy \\nof the retrieved answers. \\nLewis et al., 2020; Raffel et al., 2020  Studies involving BART and T5 show that it is \\npossible to minimize the length of the input by \\npre-summarizing the longer text before passing \\nit to the LLMs. These models assist in \\nshrinking the input size but then may lose many \\ndetails in solving a problem , resulting into \\neither a partial or an erroneous one. \\nTable 4 Litreature Review \\n \\n4.5.2 Interviews \\n \\nCodes Themes Conclusions \\nPrompt Compression, \\nInformation Preservation \\nResearch Problem The reviewed literature and \\ndiscussions emphasized that \\nprompt compression should \\nretain essential information to \\nmaintain LLM response \\nquality. Stakeholders agreed \\nthat striking a balance between \\ntoken savings and context \\npreservation is critical in RAG \\npipelines. \\nToken Efficiency, Reduced \\nQuery Costs'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 24, 'page_label': '25'}, page_content='preservation is critical in RAG \\npipelines. \\nToken Efficiency, Reduced \\nQuery Costs \\nResearch Gap Research showed that token \\nreduction stands as a primary \\noptimization technique for \\nNLP although most existing \\nRAG pipelines do not use \\nadaptive compression \\nmethods based on question \\ndifficulty level. This project \\nfills the existing gap through \\noptimized t oken management \\nfor questions and retrieved \\ndocuments. \\nAbstractive/Extractive Methodology Professionals advised using a'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 25, 'page_label': '26'}, page_content='Summarization, Multi -step \\nCompression \\ntwo-step summarization \\nmethod that combines \\nextractive with abstractive \\nmethods when working with \\npharmaceutical assessment \\ndata. A two-tier process using \\nextractive then abstractive \\napproaches ensures efficient \\ncompression without \\nsacrificing essential me dical \\ninformation or facts. \\nWebMD Dataset, Chunking \\nStrategy \\nDatasets Participants chose the \\nWebMD Drug Reviews \\ndataset together with their \\nchunking strategy as the \\noptimal combination for RAG \\nimplementation. Researchers \\nagreed that vector storage and \\nretrieval perform best when \\nparticipants conduct proper \\npre-processing while applying \\nchunking methods. \\nEmbedding Models, \\nVectorization Techniques \\nSystem Design Integrating vectorization \\ntechniques like Sentence -\\nBERT and FAISS for fast and \\naccurate retrieval was \\nhighlighted as crucial. \\nStakeholders stressed the \\nimportance of indexing vector \\nembeddings efficiently to \\nreduce retrieval latency.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 25, 'page_label': '26'}, page_content='importance of indexing vector \\nembeddings efficiently to \\nreduce retrieval latency. \\nFinal Prompt Construction, \\nCombined Queries \\nEvaluation Metrics Evaluating the combined \\nprompt (original user query + \\ncompressed retrieved \\ninformation) using token \\nefficiency, retrieval accuracy, \\nand final LLM response \\nrelevance ensures \\ncomprehensive assessment of \\nproject outcomes. \\nTable 5 Interviews'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 26, 'page_label': '27'}, page_content='2.6 Context Diagram \\nThe Context Diagram gives a general description of Dynamic Prompt Compression System for \\nLLMs and shows the ways in which DP CSS LLMs communicates with outside entities. On this \\ndiagram the system is shown in the middle with the end-users and the stakeholders placed around \\nit indicating the inputs they submit and the outputs they get. \\nEnd Users (NLP Engineers/Data Scientists): Input plain text data to the system and obtain small \\ntext data that are efficient when fed into LLMs. \\nProject Owner: Provides needful information for alteration of system and gets statistic data to \\nassess effectiveness of used system.  \\nQuality Assurance Team: Gives information about the performance of the system and receives \\nevaluation logs for the quality check.  \\nThis diagram assists in identifying the key duties and the major tasks of every stakeholder; at the \\nsame time this shows how the information between the stakeholders and the system may be'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 26, 'page_label': '27'}, page_content='same time this shows how the information between the stakeholders and the system may be \\nexchanged effectively and cohesively to define the project’s scope and interactions. \\n \\n \\nFigure 2 Context Diagram \\n \\n2.7 Use Case Diagram and Descriptions'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 27, 'page_label': '28'}, page_content='The following diagram shows the use-cases tied to the approaches that involve interactions within \\nthe system and its most important players. Furthermore, interactions between the use cases \\nwithin the have also been suggested for clarity in the system have also been indicated for better \\nunderstanding. \\n \\n2.7.1 Use Case Diagram \\n \\n2.7.2 Use Case Descriptions \\n \\n \\n \\n \\n \\n \\n2.8 Functional and Non-Functional Requirements \\n2.8.1 Functional Requirements (FR) \\nThese requirements define the core functions that the system must perform to achieve its \\nobjectives. \\n \\nID Requirement Priority (MoSCoW) Description \\nFR1 The system shall \\naccept user queries \\nthrough the front-end. \\nMust Have Users can input \\nquestions related to \\ndrugs or treatments. \\nFR2 The system shall \\nretrieve relevant \\nchunks from the \\nvectorized database. \\nMust Have The retrieval should \\nbe based on FAISS \\nand embedding -based \\nsimilarity search. \\nFR3 The system shall \\ncompress retrieved \\ndata using extractive'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 27, 'page_label': '28'}, page_content='similarity search. \\nFR3 The system shall \\ncompress retrieved \\ndata using extractive \\nand abstractive \\nmethods. \\nMust Have Compress the \\nretrieved chunks \\nusing the multi -step \\ncompression \\napproach. \\nFR4 The system shall \\ncombine the user \\nquery and compressed \\ncontent into a final \\nprompt \\nMust Have The combined prompt \\nis formatted for \\noptimal input to the \\nLLM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 28, 'page_label': '29'}, page_content='FR5 The system shall pass \\nthe final prompt to an \\nLLM to generate \\nresponses. \\nMust Have Utilize an OpenAI \\nAPI or other LLM for \\nanswer generation. \\nFR6 The system shall \\nprovide an option for \\nusers to copy the final \\ncompressed prompt. \\nShould Have Users can copy the \\ncompressed prompt \\nfor further use. \\nFR7 The system shall \\ndisplay relevant drug \\nnames alongside the \\nsummarized \\nresponses. \\nShould Have Provide drug context \\nwithin the final output \\nto ensure clarity. \\nFR8 The system shall log \\nuser queries and \\nresponses for \\nperformance \\nevaluation. \\nCould Have Maintain a log to \\nanalyze and refine the \\nretrieval and \\ncompression process. \\nTable 6 Functional Requirements \\n2.8.2 Non-Functional Requirements (NFR) \\n \\nID Requirement Priority (MoSCoW) Description \\nNFR1 The system shall \\nprovide responses \\nwithin 5 seconds of \\nquery submission. \\nMust Have Ensures acceptable \\nsystem response time \\nfor user interaction. \\nNFR2 The system shall \\nmaintain high \\nretrieval accuracy'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 28, 'page_label': '29'}, page_content='for user interaction. \\nNFR2 The system shall \\nmaintain high \\nretrieval accuracy \\nwith minimal token \\nloss. \\nMust Have The token \\ncompression must \\npreserve important \\ncontext for generating \\naccurate responses. \\nNFR3 The system shall \\nsupport scalability \\nwith large medical \\ndatasets. \\nShould Have The system must \\nhandle large datasets \\n(e.g., WebMD \\nreviews) efficiently \\nfor scalable operation. \\nNFR4 The system shall be Should Have Simple and intuitive'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 29, 'page_label': '30'}, page_content='user-friendly and \\neasy to navigate for \\nnon-technical users. \\ninterface design to \\nensure ease of access \\nto features. \\nNFR5 The system shall \\nensure data security \\nand privacy. \\nMust Have User queries and \\nretrieved data should \\nbe protected from \\nunauthorized access. \\nNFR6 The system shall \\nallow for easy \\nupdates to embedded \\nmodels and \\nsummarization \\ntechniques. \\nCould Have Modular architecture \\nto allow replacing \\nmodels without \\naffecting the overall \\nsystem. \\nNFR7 The system shall \\nmaintain minimal \\ncomputational \\noverhead during \\ncompression. \\nShould Have Ensure that the \\ncompression process \\ndoes not introduce \\nsignificant delays. \\nNFR8 The system shall \\nprovide high \\navailability and \\nreliability. \\nCould Have Ensure minimal \\ndowntime and \\nconsistent \\nperformance across \\nuse cases. \\nTable 7 Non - Functional Requirements \\n \\n2.9 Chapter Summary \\nThe chapter on the Software Requirement Specification has given an understanding of the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 29, 'page_label': '30'}, page_content='The chapter on the Software Requirement Specification has given an understanding of the \\nfunctional and non-functional requisition of the system, how these requirements are elicited, and \\nthe procedures as well as tools and techniques that have been adopted to meet the stakeholder’s \\nneeds. The system requirements were prioritised according to the MoSCoW principle to identify \\nwhat is must have for the success of the system.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 30, 'page_label': '31'}, page_content='Chapter 3: Design \\n3.1 Chapter Overview \\nThe design determinations for developing an appropriate system architecture will receive detailed \\nanalysis in this chapter. The design of the proposed system stems from requirements identification \\nin an earlier chapter. First, the The identified design goa ls will be displayed in a table structure \\nwhile high-level design together with low level design and system process flow chart along with \\nUI wireframes will be presented.The creation of system process flow charts together with UI \\nwireframes stands alongsid e other associated design diagrams. A complete rationale backs each \\ndecision during design. \\n3.2 Design Goals \\n \\nDesign Goal Description \\nPerformance Research Component : The integration of \\nprompt compression into RAG pipelines must \\ndemonstrate improved efficiency in generating \\naccurate responses while optimizing token \\nusage. The system should minimize the \\nnumber of tokens while maintaining response \\nrelevance.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 30, 'page_label': '31'}, page_content='usage. The system should minimize the \\nnumber of tokens while maintaining response \\nrelevance. \\n \\nPrototype Component: The prototype should \\nensure that prompt compression and retrieval \\ndo not introduce significant latency, aiming for \\nresponse times within user -acceptable limits \\n(e.g., under 5 seconds). \\nAdaptability The system should be adaptable to different \\nknowledge bases and datasets. While this \\nproject focuses on the WebMD Drug Review \\nDataset, the architecture should allow easy \\nextension to other medical or domain -specific \\ndatasets without requiring significant redesign. \\nUsability Since the application targets both technical and \\nnon-technical users, the user interface (via \\nStreamlit) should be clean, minimalistic, and \\nintuitive. Features such as copyable \\ncompressed prompts, easy input of user \\nqueries, and accessible feedback mechanisms \\nshould be emphasized to ensure a positive user \\nexperience.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 31, 'page_label': '32'}, page_content='Scalability The RAG pipeline should be capable of scaling \\nhorizontally to handle large medical datasets \\n(e.g., millions of records). The FAISS index \\nand vectorization processes should efficiently \\nretrieve relevant information even as the \\ndataset grows. \\nCorrectness Compression Accuracy : The compressed \\nprompt must preserve key facts and important \\ncontext to ensure that LLM responses are \\ncorrect and contextually appropriate. \\nInformation Retrieval : Ensure the retrieval \\nmechanism correctly identifies relevant \\nreviews and minimizes irrelevant or redundant \\ndata. \\nMaintainability  \\n \\n \\nThe system architecture should be modular, \\nallowing for future updates or replacements \\nof the embedding models, retrieval \\nmechanism, or compression strategies \\nwithout affecting the overall system. \\nDocumentation and code structure should \\nsupport ease of mai ntenance and future \\nimprovements.  \\nSecurity and Privacy Given that the system involves sensitive'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 31, 'page_label': '32'}, page_content='improvements.  \\nSecurity and Privacy Given that the system involves sensitive \\nmedical data, it is important to follow best \\npractices for data security, ensuring that \\nqueries, retrieved data, and responses are \\nproperly encrypted and protected from \\nunauthorized access. The design should also \\nensure that user interaction data is handled in \\ncompliance with data privacy regulations. \\nTable 8 Design Goals \\n \\n \\n \\n3.3 System Architecture Design \\n \\n3.3.1 Architecture Diagram'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 32, 'page_label': '33'}, page_content='The project demands a tiered model which separates presentation from logic from data tiers. The selection \\nof a system architecture that separated physical components between tiers occurred because of the project \\nrequirements. The following diagram the different components which exist within their corresponding tiers. \\nThe Presentation tier deals User Interface components of the system receive input from end users while \\nData tier manages data storage and retrieval operations. The data management system throug h the Logic \\ntier connects presentation and data functions by enabling system functionality functionalities of the system. \\n \\n \\nFigure 3 Architecture Diagram \\n \\n \\n \\n \\n \\n \\n3.3.2 Discussion of Tiers \\nPresentation Tier'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 33, 'page_label': '34'}, page_content='User Input Box: \\n● Description: This is the interface where the user enters their query. It serves as the main \\ninteraction point between the user and the system. \\nSubmit Button: \\n● Description: A button to initiate the process. When clicked, it triggers the query processing \\nand retrieval workflow. \\nFinal Display Box: \\n● Description: Displays the summarized response generated by the system, combining the \\noriginal query with relevant compressed data. \\nDownload Button: \\n● Description: Allows users to download the final prompt containing the query and retrieved \\nsummary. \\nCopy Button: \\n● Description: Enables users to copy the final prompt to the clipboard for use in other \\napplications. \\n \\nLogic Tier \\nQuery Processing Module: \\n● Description: Converts the user’s input into vector form using an embedding model. It \\nensures the query is properly formatted for search and retrieval. \\nRetriever Module: \\n● Description: Searches the FAISS index to find the most relevant preprocessed chunks'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 33, 'page_label': '34'}, page_content='● Description: Searches the FAISS index to find the most relevant preprocessed chunks \\ncorresponding to the user query. \\nHybrid Compression Module: \\n● Description: Applies extractive and abstractive summarization techniques to compress \\nthe retrieved chunks into a concise, informative summary. \\nEvaluation Module:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 34, 'page_label': '35'}, page_content='● Description: Evaluates the output of the system using metrics such as ROUGE, \\nBERTScore, and Recall @ K to ensure quality and effectiveness of the retrieved and \\ncompressed data. \\n \\nData Tier \\n1. WebMD Drug Reviews Dataset: \\n○ Description: Contains the raw data, including drug reviews, side effects, dosage \\ndetails, and user experiences. \\n2. Preprocessed Review Chunks: \\n○ Description: The dataset is split into smaller, manageable chunks for efficient \\nprocessing and embedding. \\n3. Embedding Storage: \\n○ Description: Stores the vector representations of the review chunks generated \\nusing Sentence-BERT. These vectors are used for efficient similarity searches. \\n4. FAISS Index: \\n○ Description: An optimized search index that facilitates fast retrieval of the most \\nrelevant chunks based on the query’s vector representation. It acts as the core \\nretrieval engine for the system. \\n \\n \\n \\n3.4 Detailed Design \\n● Purpose: Provide an in-depth look at system components. \\n● Content:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 34, 'page_label': '35'}, page_content='3.4 Detailed Design \\n● Purpose: Provide an in-depth look at system components. \\n● Content: \\no Use diagrams like class, sequence, or flow diagrams. \\no Explain how each component supports the system’s goals. \\n \\n3.5 Algorithm Design \\nThis section presents the design of the key algorithms used in the project. The algorithms focus on \\nprocessing user queries, retrieving relevant review chunks using the FAISS index, applying hybrid \\ncompression, and generating optimized responses.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 35, 'page_label': '36'}, page_content='Key Algorithms and Pseudocode: \\n1. Algorithm: Query Embedding and Retrieval using FAISS Index \\nConvert the user’s natural language query into an embedding and retrieve the most relevant \\nreview chunks using FAISS similarity search. \\n \\nFigure 4 Query Embedding \\n2. Algorithm: Hybrid Compression \\nCompress the retrieved chunks by combining extractive and abstractive summarization. \\nFirst, extract sentences containing key phrases, and then refine the summary using a \\nlanguage model. \\n \\nFigure 5 Hybrid Compression \\n3. Algorithm: Final Prompt Generation \\nCombine the user query with the compressed information to generate a final prompt for the \\nLLM.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 36, 'page_label': '37'}, page_content='3.6 UI Design Wireframe \\n \\nFigure 7 UI Wireframe \\nFigure 6 Prompt Generation'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 37, 'page_label': '38'}, page_content='3.7 Chapter Summary \\nThe chapter provided an in -depth description of system design including the methodologies that \\nwould be used during the implementation of the proposed solution. Design goals led the \\ndevelopment of high-level and low-level architectural components which were structured through \\nrelevant design diagrams. The selected software design paradigm received justification while the \\nsystem design included supporting diagrams which displayed components and data flow and \\nprocess flow and user interfaces. System implementation details will be discussed in the following \\nchapter according to design outline specifications.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 38, 'page_label': '39'}, page_content='Chapter 4: Implementation \\n4.1 Chapter Overview \\nThe author provides comprehensive documentation regarding every aspect of the implementation \\nworkflow for the designed prototype. The system architecture advanced through combination of \\nknowledge derived from the literature review and requirement elicitati on phases, suitable \\ntechnologies and development frameworks have been selected. The selected technological choices \\nreceive adequate justification. The core functionality implementation details receive support \\nthrough code examples that accompany the provided information. \\n \\n \\n4.2 Technology Selection \\n4.2.1 Technology Stack \\nThe following figure represents the technologies selected to for the implementation and \\nfunctionality of the designed 3-tier architecture. \\n \\nPresentation Tier \\n \\n \\nLogic Tier'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 39, 'page_label': '40'}, page_content='Data Tier  \\n \\n \\nTable 9 Technology Stack \\n4.2.2 Dataset Selection \\nSeveral specialized data collections for drug reviews and user queries were selected from literature \\nreview findings and requirement gathering to support information retrieval and compression \\nfunctions along with language modeling. \\n \\nDataset Type Purpose \\nWebMD Drug Reviews \\nDataset \\nSpecialized dataset of drug \\nreviews \\nThe database functions as the \\nmain drug review platform \\nwhich collects user feedback \\nabout medication conditions \\nand performance together with \\nreported side effects. The \\nreviews will undergo \\nsegmentation followed by \\nvectorization so they can be \\nretrieved d uring query \\nexecution. \\nUCI ML Drug Review Dataset Generalized dataset on drug \\nreviews \\nThe system provides \\nsupplementary information to \\nenlarge search parameters and \\nachieve better query retrieval \\nperformance. The method'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 40, 'page_label': '41'}, page_content='delivers retrieval results that \\ninclude comprehensive \\nfindings which maintain their \\nvalidity across different drug \\nconditions. \\nKaggle Health -Related \\nDatasets \\nHealth-specific user feedback The system offers additional \\ndomain-specific datasets that \\nenable the retrieval pipeline to \\nexpand its knowledge base \\nfrom more user experiences \\nand medical review \\ndocuments. \\nPre-trained Sentence \\nEmbedding Models (e.g., all -\\nMiniLM-L6-v2) \\nEmbedding models The system converts all user \\nqueries and retrieved chunks \\ninto vectorized formats which \\nallows FAISS indexing to \\nperform similarity -based \\nquery matching. \\nSumy-based Summarization \\nOutputs \\nCompressed summary of \\nretrieved data \\nThe system performs efficient \\nprompt compression by using \\nextractive and abstractive \\nsummarization methods \\nbefore delivering the prompt \\nto the LLM. \\nTable 10 Dataset Selection \\n \\n \\n4.2.3 Programming Languages \\n \\nProgramming Language Reasoning \\nPython Python is chosen as the primary programming'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 40, 'page_label': '41'}, page_content='Programming Language Reasoning \\nPython Python is chosen as the primary programming \\nlanguage for building the core system, \\nincluding data preprocessing, chunking, \\nvectorization, retrieval, and compression. Its \\nextensive library support (e.g., \\nSentenceTransformers, faiss, \\npandas, and transformers) and active'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 41, 'page_label': '42'}, page_content='community make it ideal for machine learning \\nand natural language processing tasks. \\nReact (JavaScript) The front-end interface of the application uses \\nReact for user interaction improvement. The \\ncomponent-based structure of this design \\nfacilitates automatic content delivery which \\nenables efficient display of retrieved \\ncompressed prompts in real-time fashion. \\nHTML & CSS The front -end components of the system \\nreceive their structure and style design from \\nBootstrap to maintain a clean interface that is \\neasy to use and accessible to users. \\n \\n \\nTable 11 Programming Languages \\n4.2.4 Libraries/Toolkits \\nBased on the selected programming languages, development frameworks, and system architecture, \\nthe following libraries and toolkits were chosen to support the development of the RAG pipeline \\nwith prompt compression functionality. These libraries enhance the  system’s ability to perform \\nretrieval, compression, vectorization, and efficient front-end interactions.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 41, 'page_label': '42'}, page_content='retrieval, compression, vectorization, and efficient front-end interactions. \\n \\nLibrary / Toolkit Rationale \\nPyTorch  A machine learning model utilizing \\nPyTorch was chosen to develop and optimize \\nany extra models required for prompt \\ncompression or vectorization functions. The \\ndynamical computation graph in combination \\nwith strong support capabilities makes \\nPyTorch suitable for research-based work. \\nSentence-BERT This library, based on PyTorch and Hugging \\nFace’s transformers, is used for query encoding \\nand dataset vectorization. It enables the \\ngeneration of dense vector embeddings for \\neffective retrieval. \\nFaiss Faiss is crucial for efficiently indexing and \\nsearching through vectorized representations \\nof the drug review dataset, enabling fast \\nretrieval of relevant knowledge chunks.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 42, 'page_label': '43'}, page_content='NumPy Used for performing numerical and matrix -\\nbased operations, including embedding \\nmanipulation, vector computations, and other \\nmathematical tasks required in the data \\nretrieval and summarization process. \\nPandas Pandas is used for handling, filtering, and \\nprocessing the drug review dataset. It allows \\neasy manipulation of tabular data and chunk \\ncreation necessary for the retrieval pipeline. \\nSpaCy SpaCy is used for sentence tokenization and \\nsplitting during extractive and abstractive \\ncompression. It supports linguistic analysis and \\nis useful in refining tokenized text for better \\ncompression. \\nSumy The Sumy library is utilized for performing \\nextractive summarization through algorithms \\nlike LSA. It assists in reducing the size of \\nretrieved chunks before combining them into \\nthe final prompt. \\nScikit-Learn Scikit-Learn is employed for data pre -\\nprocessing, vector manipulation, and \\npotentially integrating additional evaluation \\ntechniques for compression effectiveness.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 42, 'page_label': '43'}, page_content='potentially integrating additional evaluation \\ntechniques for compression effectiveness. \\nStreamlit Streamlit simplifies the creation of an \\ninteractive front -end interface for user input, \\ndisplaying retrieved results, and interacting \\nwith the underlying retrieval and compression \\nmodels. \\nTable 12 Library Toolkit \\n4.3 Core Functionalities Implementation \\nThe RAG Pipeline with prompt compression operates through a modular design that splits \\nresponsibilities between different modules to gather and condense appropriate information before \\ncreating the final prompt presentation. The system consists of fundament al modules with this \\nfollowing description: \\n \\nModule Purpose Relation to Functional \\nRequirements (Chapter 2)'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 43, 'page_label': '44'}, page_content='Data Preprocessing This module \\n(download_dataset.py) \\nprepares the dataset by \\ncleaning, splitting, and \\ncreating vector embeddings of \\nreview chunks using \\nSentence-BERT. \\nEnsures that data is ready for \\nretrieval, supporting the \\nrequirement of efficient data \\nprocessing. \\nVector Database FAISS-based indexing \\n(vector_database.py) \\nto store and retrieve the \\nvectorized review chunks \\nefficiently. \\nSupports retrieval of top -k \\nrelevant chunks from large \\ndatasets. \\nUser Query Encoding Converts the user query into a \\nquery vector using Sentence -\\nBERT (user_query.py). \\nAllows retrieval of relevant \\nreview chunks in response to \\nuser input. \\nChunk Summarization and \\nCompression \\nApplies both extractive \\n(keyword-based) and \\nabstractive (BART -based) \\nsummarization to retrieved \\nchunks (user_query.py & \\nstreamlit_app.py). \\nCompresses retrieved data to \\nprovide a concise, context-rich \\nprompt. \\nStreamlit Frontend Provides a user -friendly \\ninterface where users can'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 43, 'page_label': '44'}, page_content='prompt. \\nStreamlit Frontend Provides a user -friendly \\ninterface where users can \\ninput queries and view the \\nsummarized output \\n(streamlit_app.py). \\nSupports user interaction and \\nvisual presentation of the \\ngenerated prompts. \\nTable 13 Core Functionality Implementation \\n \\nCode Structure \\n \\nThe code uses modular programming principles and follows key scripts which maintain \\nseparation of concerns and ensure code maintainability. \\n \\n1. Preprocessing and Data Preparation \\n \\n● Cleans the dataset (removes duplicates and nulls). \\n● Splits large reviews into manageable chunks. \\n● Generates and saves embeddings using Sentence-BERT.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 44, 'page_label': '45'}, page_content='2. Embedding Generation \\n \\n \\n \\n \\n \\n3. FAISS Index Initialization \\n \\n \\n \\n \\n4. Query Vectorization and Retrieval'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 45, 'page_label': '46'}, page_content='5. Summarization and Final Prompt \\n \\n \\n \\n \\n \\n4.4 User Interface Implementation \\n4.4.1 Frontend Development'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 46, 'page_label': '47'}, page_content='Streamlit served as the development framework for creating the application frontend through its \\nPython-based web application construction system. The application shows a focus on basic design \\nwith intuitive controls and provides detailed results to user requests. \\n \\nUI Element Description \\nText Input Box Users should enter their drug review -related \\nquestions or queries through a basic text entry \\nfield. \\nSubmit Button The \"Get Response\" button activates \\ninformation retrieval along with summary \\ngeneration after click activation. \\nFinal Prompt Display The output shows the combined prompt that \\nincludes both the user query and compressed \\ninformation retrieved from the sources. \\nCopy Prompt Button The application enables users to transfer the \\nfinal prompt output into a text file which they \\ncan utilize or document. \\nWarning/Validation Messages The interface shows alerts to users who \\nabandon input fields or submit non -valid \\nsearch terms. \\nTable 14 UI Elements'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 46, 'page_label': '47'}, page_content='abandon input fields or submit non -valid \\nsearch terms. \\nTable 14 UI Elements \\n4.4.2 Backend Integration \\nThe backend is responsible for handling user queries, retrieving relevant information using the \\nFAISS index, and compressing the information using abstractive summarization. The interaction \\nbetween the frontend and backend is as follows: \\n1. User Input: The user submits a query via the input box on the frontend. \\n2. Query Processing: The backend encodes the user query using the Sentence-BERT model \\nand retrieves the most relevant chunks from the FAISS index. \\n3. Compression and Summarization: The retrieved chunks are processed by the backend’s \\nsummarization component, which generates a compressed and meaningful response. \\n4. Result Display: The final prompt is returned to the frontend and displayed for the user.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 47, 'page_label': '48'}, page_content='User Interface \\n \\n \\n \\n>> Next Page'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 48, 'page_label': '49'}, page_content='Figure 8 User Interface'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 49, 'page_label': '50'}, page_content='4.5 Challenges and Solutions \\nThe deployment of the RAG pipeline with prompt compression required handling multiple \\nobstacles which emerged during development. This section analyzes significant obstacles that \\nemerged during project implementation together with their project effect and the implemented \\nsolutions for optimization. \\n \\nChallenge Description Solution \\n Slow Query Execution The retrieval process using the \\nFAISS index initially \\nexhibited delays, especially \\nwhen handling large datasets \\nand complex user queries. \\nOptimized the FAISS index by \\nprecomputing and storing \\nembeddings efficiently. \\nReduced top -k search range \\nand experimented with \\ndistance metrics. \\nLarge Embedding File Size The vectorized embeddings \\n(stored in \\nembeddings.npy) \\nconsumed significant disk \\nspace and memory during the \\nretrieval process. \\nCompressed embeddings \\nusing dimensionality \\nreduction techniques (e.g., \\nPCA). Implemented chunk -\\nbased data loading to handle \\nmemory constraints.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 49, 'page_label': '50'}, page_content='PCA). Implemented chunk -\\nbased data loading to handle \\nmemory constraints. \\nSummarization Model \\nPerformance \\nThe abstractive \\nsummarization model \\n(facebook/bart-\\nlarge-cnn) initially \\nstruggled with long retrieved \\nchunks, resulting in \\nincomplete summaries. \\nApplied extractive \\ncompression using keyword \\nprioritization to reduce the text \\nbefore passing it to the \\nsummarization model. \\nInconsistent Query Results The results retrieved from the \\nFAISS index were sometimes \\ninconsistent due to \\nimbalanced or sparse review \\ncontent. \\nImproved dataset \\npreprocessing by splitting and \\nfiltering chunks for better \\nrelevance. Balanced training \\nusing diverse and complete \\nreview texts. \\nNLTK Tokenizer Errors Errors were encountered when \\ntokenizing long or irregular \\nreview texts using NLTK’s \\nsent_tokenize(). \\nUpdated the tokenization \\nprocess to handle irregularities \\nby combining NLTK with \\nSpacy’s robust sentence \\nsegmentation for fallback \\ncases.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 50, 'page_label': '51'}, page_content='High Latency in Streamlit \\nApplication \\nThe Streamlit frontend faced \\nperformance bottlenecks when \\nretrieving and displaying \\nresults in real time. \\nImplemented Streamlit \\ncaching mechanisms using \\n@st.cache and optimized \\nthe communication between \\nfrontend and backend using \\nasynchronous updates. \\nAbstractive Summarization \\nOutput Quality \\nSummarization often \\nproduced vague or overly \\ngeneric responses due to lack \\nof context from input chunks. \\nIntroduced a two -stage \\ncompression: extractive \\n(keyword-prioritized) \\nfollowed by abstractive \\nsummarization, ensuring \\nimportant details were \\nretained. \\nIntegration Issues Between \\nFrontend and Backend \\nCommunication between the \\nfrontend UI and backend \\nmodules sometimes failed due \\nto inconsistent data formats \\n(e.g., lists vs strings). \\nStandardized data exchange \\nformats between the frontend \\nand backend by ensuring that \\nall intermediate data structures \\nfollowed JSON or Pandas \\nDataFrames. \\n Dataset Quality and Noisy \\nReviews'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 50, 'page_label': '51'}, page_content=\"followed JSON or Pandas \\nDataFrames. \\n Dataset Quality and Noisy \\nReviews \\nThe WebMD Drug Reviews \\ndataset contained noisy data \\n(e.g., incomplete reviews, \\nirrelevant information). \\nCleaned the dataset by \\napplying preprocessing \\ntechniques such as stop -word \\nremoval, filtering duplicates, \\nand handling missing data \\nefficiently. \\nUser Interface \\nResponsiveness \\nEnsuring that the application \\nremained responsive and \\nusable on various devices and \\nscreen sizes was challenging. \\nDesigned a minimalistic UI \\nusing Streamlit with \\nresponsive design elements. \\nEnhanced user feedback \\nthrough warning messages \\nand status indicators. \\nTable 15 Challengers and Solutions \\n \\n4.6 Chapter Summary \\nThe project's implementation phase concentrated on designing and uniting essential components \\nfor the Retrieval -Augmented Generation (RAG) pipeline alongside prompt compression \\ntechniques. This chapter details the implementation process by describing technology choices and\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 50, 'page_label': '51'}, page_content='techniques. This chapter details the implementation process by describing technology choices and \\ndemonstrates how major modules operated alongside the resolution of encountered challenges.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 51, 'page_label': '52'}, page_content='Chapter 5: Testing \\n \\n5.1 Chapter Overview \\n \\nThis chapter explains the entire testing process in detail along with its essential role to establish \\nquality standards for the developed prototype. The testing process includes multiple elements \\nstarting from testing objectives to model testing through be nchmarking before conducting \\nfunctional and non-functional tests and module and integration tests and ending with identification \\nof testing limitations. This section will explore all the constraints which affect the testing \\nprocedure. \\n \\n \\n5.2 Testing Criteria \\n1. Functional Requirements Validation \\nTests Conducted: \\n● Query Submission: Verify that user inputs are correctly processed and encoded. \\n● Data Retrieval: Validate that the system retrieves the top-k relevant review chunks \\nfrom the FAISS index based on the user query. \\n● Prompt Compression:  Ensure that retrieved chunks are compressed correctly \\nthrough extractive and abstractive summarization.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 51, 'page_label': '52'}, page_content='through extractive and abstractive summarization. \\n● Prompt Generation: Confirm that the final prompt combines the user query and \\ncompressed information correctly and is ready for downstream LLM usage.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 52, 'page_label': '53'}, page_content='2. Non-Functional Requirements Evaluation \\n \\nNon-Functional \\nRequirement \\nDescription Metric Used Target Value \\nSpeed Measure the time \\ntaken to process \\nuser queries, \\nretrieve results, and \\ngenerate final \\nprompts. \\nAverage Response \\nTime \\n≤ 2 seconds \\nfor most \\nqueries \\nScalability Ensure the system \\ncan handle larger \\ndatasets without \\nsignificant \\nperformance \\ndegradation. \\nThroughput Testing Efficient response \\ntime for up to 1M \\nreview records. \\nReliability Ensure consistent \\noutput and robust \\nerror handling in \\ncase of data or \\nsystem failures. \\nSuccess Rate of \\nQueries \\n≥ 99% \\nsuccessful \\nresponses. \\nUsability Ensure that the \\ninterface is intuitive \\nand user-friendly. \\nUser Feedback \\nRating \\n≥ 4/5 based on \\nend-user \\ntesting. \\nTable 16 Non-Functional Requirements \\n3. Model Performance Metrics \\nThe retrieval and compression processes depend on model accuracy and relevance. \\nTherefore, model performance metrics are evaluated as follows: \\n \\nMetric Description Target'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 52, 'page_label': '53'}, page_content='Therefore, model performance metrics are evaluated as follows: \\n \\nMetric Description Target \\nROUGE-1, ROUGE-2, \\nROUGE-L \\nMeasures overlap between \\nretrieved or compressed \\ninformation and expected \\noutputs. \\n≥ 0.5 average score.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 53, 'page_label': '54'}, page_content='BERTScore Measures the semantic \\nsimilarity between \\nretrieved/compressed \\nchunks and the gold -\\nstandard text. \\nPrecision ≥ 0.85, \\nRecall ≥ 0.80 \\nRecall @ k Measures how many of the \\nrelevant chunks are \\nretrieved within the top -k \\nresults. \\n≥ 80% of relevant \\nchunks retrieved. \\nCompression Ratio  \\n \\n \\nEvaluates how effectively \\nthe retrieved data is \\ncompressed while \\npreserving key \\ninformation.  \\nTarget ratio ≤ 10:1 \\nPerplexity (LLM \\nEvaluation) \\nMeasures how well the \\nprompt is understood by the \\ndownstream LLM. \\nAcceptable levels for low \\nperplexity. \\n \\n \\nTable 17 Model Performance Metrics'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 54, 'page_label': '55'}, page_content='Output Results: \\n \\n \\n \\n5.3 Functional Testing \\n \\nTest Case FR ID User Action Expected \\nOutcome \\nActual \\nOutcome \\nResult Status \\n1 FR1 User enters a drug-\\nrelated query (e.g., \\n\"What are the side \\neffects of \\nibuprofen?\") into \\nthe Streamlit input \\nbox and clicks \"Get \\nResponse.\" \\nThe system \\nprocesses the \\nquery, retrieves \\nrelevant review \\nchunks, and \\ndisplays the final \\ncompressed \\nprompt. \\nThe system \\nsuccessfully \\nprocessed the \\nquery, retrieved \\nrelevant \\nchunks, and \\ndisplayed the \\nfinal prompt. \\nPassed \\n2 FR2 User submits an \\nempty query by \\nclicking \"Get \\nResponse\" without \\nentering any input. \\nA warning \\nmessage is \\ndisplayed, \\nprompting the \\nuser to enter a \\nquery. \\nThe system \\ndisplayed a \\nwarning \\nmessage: \\n\"Please enter a \\nquery to get \\nstarted.\" \\nPassed \\n3 FR3 User submits a The top -10 most The system Passed'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 55, 'page_label': '56'}, page_content='valid query, and \\nthe system \\nretrieves and \\ncompresses the \\ntop-10 relevant \\nchunks. \\nrelevant chunks \\nare retrieved, \\ncompressed, and \\nincluded in the \\nfinal output. \\nsuccessfully \\nretrieved and \\nsummarized \\nthe top -10 \\nchunks with \\nrelevant drug \\nreviews. \\n4 FR4 User clicks the \\n\"Download Final \\nPrompt\" button to \\ndownload the \\ncompressed \\nprompt as a text \\nfile. \\nThe compressed \\nprompt is \\ndownloaded to \\nthe user’s device \\nas \\nfinal_promp\\nt.txt. \\nThe system \\nsuccessfully \\ndownloaded \\nthe file to the \\nuser’s device. \\nPassed \\n5 FR5 User enters a query \\ncontaining \\nkeywords like \\n\"side effects\" or \\n\"treatment\" and \\nsubmits it. \\nThe system \\nprioritizes \\nsentences \\ncontaining \\nkeywords and \\nuses them for \\nextractive \\nsummarization. \\nSentences \\ncontaining the \\nrelevant \\nkeywords were \\nprioritized and \\nincluded in the \\ncompressed \\nprompt. \\nPassed \\n6 FR6 User submits a \\nquery, and the \\nevaluation metrics \\nare computed after \\nthe final prompt \\ngeneration. \\nROUGE, \\nBERTScore, and'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 55, 'page_label': '56'}, page_content='evaluation metrics \\nare computed after \\nthe final prompt \\ngeneration. \\nROUGE, \\nBERTScore, and \\nRecall @ k \\nmetrics are \\ndisplayed in the \\nStreamlit \\ninterface. \\nEvaluation \\nmetrics \\n(ROUGE, \\nBERTScore, \\nRecall @ k) \\nwere correctly \\ncalculated and \\ndisplayed in the \\nUI. \\nPassed \\n7 FR7 User submits a \\nquery, and the \\nsystem performs \\nend-to-end \\nexecution, from \\nquery input to \\nprompt display. \\nThe system \\nprocesses the \\nquery, retrieves \\nrelevant \\ninformation, and \\ndisplays the \\ncompressed \\nprompt. \\nThe system \\nsuccessfully \\nexecuted the \\nend-to-end \\nworkflow, \\ndisplaying the \\nprompt within \\nacceptable \\ntime. \\nPassed \\n8 FR8 User submits The system The system Passed'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 56, 'page_label': '57'}, page_content='multiple queries in \\nsuccession to test \\nsystem \\nresponsiveness and \\nperformance. \\nresponds within 5 \\nseconds for each \\nquery and \\nmaintains \\nconsistent results. \\nmaintained \\nconsistent \\nresponse times \\nand displayed \\naccurate \\ncompressed \\nprompts for \\neach query. \\nTable 18 Functional Testing \\n \\n5.4 Non-Functional Testing \\n5.4.1 Performance Testing \\nObjective: Evaluate the system’s response times under different loads, ensuring the query \\nprocessing and retrieval mechanisms perform within acceptable limits. \\n \\nTest Scenario Load Condition Expected \\nResponse Time \\nActual \\nResponse Time \\nResult Status \\nSingle user \\nquery \\n1 user submitting \\na query \\n≤ 2 seconds 1.8 seconds Passed \\nMultiple \\nconcurrent users \\n(5 users) \\nSimulate 5 \\nconcurrent \\nqueries to test \\nsmall user load \\n≤ 3 seconds 2.3 seconds Passed \\nHeavy load (50 \\nusers) \\nYet to be tested \\nLarge dataset \\nretrieval \\nYet to be tested'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 57, 'page_label': '58'}, page_content='5.4.2 Scalability Testing \\n \\nTest Scenario Condition Expected \\nOutcome \\nActual Outcome Result Status \\nIncreasing \\ndataset size \\nNot yet tested \\nIncreasing \\nnumber of \\nconcurrent users \\nNot yet tested \\nHigh-frequency \\nqueries \\nNot yet tested \\n \\n5.4.3 Usability Testing \\n \\nUsability Criteria Evaluation Method Feedback / Outcome Improvements \\nSuggested \\nEase of Use Heuristic evaluation \\n(Nielsen’s heuristics) \\nMost users found the \\ninterface intuitive, \\nespecially for entering \\nqueries and viewing \\nresults. \\nDisplay sample drug \\nqueries (e.g., “What is \\nibuprofen used for?”) \\non the main page for \\nbetter guidance. \\nTask Efficiency User feedback session \\n(5 participants) \\nUsers could retrieve \\nsummarized prompts \\nwithin 2 -3 \\ninteractions. \\nNone suggested. \\nError Prevention Heuristic evaluation The system displayed \\nappropriate warning \\nmessages for empty or \\ninvalid inputs. \\nNo significant \\nimprovements \\nsuggested. \\nOutput Presentation User feedback session Users liked the clear'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 57, 'page_label': '58'}, page_content='improvements \\nsuggested. \\nOutput Presentation User feedback session Users liked the clear \\npresentation of the \\nfinal prompt and \\nevaluation metrics. \\nSuggestion to display \\nevaluation metrics in a \\ntabular format for \\neasier interpretation. \\nTable 19 Usability Testing'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 58, 'page_label': '59'}, page_content='5.5 Model Testing (for ML Projects) \\n5.5.1 Dataset Testing \\nDatasets Used: \\n1. WebMD Drug Reviews Dataset: The primary dataset containing real-world user reviews \\nof medications and their side effects. \\n2. Synthetic Queries: Custom queries were generated to simulate different user intents and \\nensure robustness under various conditions. \\n \\nTest Scenario Dataset Used Objective Result \\nQuery with clear \\nintent \\nWebMD dataset Validate that the \\nsystem retrieves and \\nsummarizes relevant \\nchunks accurately for \\nqueries with direct \\nintent \\nRetrieved relevant \\nchunks and generated \\na prompt with \\nBERTScore F1 of \\n0.87 and ROUGE -1 \\nscore of 0.55. \\nAmbiguous queries WebMD dataset + \\nsynthetic queries \\nTest system \\nperformance when \\nhandling ambiguous \\nqueries (e.g., \"What is \\nit used for?\"). \\nRetrieved chunks \\ncovered multiple \\ninterpretations of the \\nquery. Prompt \\ngeneration had a \\nBERTScore F1 of \\n0.78. \\nUnseen data Synthetic drug review \\ndata \\nEvaluate the \\nsummarization \\nperformance on'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 58, 'page_label': '59'}, page_content='0.78. \\nUnseen data Synthetic drug review \\ndata \\nEvaluate the \\nsummarization \\nperformance on \\nunseen reviews. \\nSummarized outputs \\npreserved key content, \\nwith ROUGE -1 of \\n0.58 and ROUGE -L \\nof 0.51. \\nDiverse user queries WebMD + synthetic \\nqueries \\nValidate system \\nperformance for \\nvarying query lengths \\nand contexts. \\nMaintained relevant \\nsummaries with \\nBERTScore Precision \\nof 0.88 across \\ndifferent query types. \\nTable 20 Dataset Testing'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 59, 'page_label': '60'}, page_content='5.6 Edge Case Testing \\nMultiple tests of the RAG Pipeline with prompt compression were conducted to determine its \\nbehavior during unexpected situations and abnormal and extreme conditions. The testing protocol \\nincluded scenarios with empty or nonsensical queries as well as large datasets and hardware failure \\nconditions along with high concurrent usage to verify meaningful system output. \\n \\nTest Case Test Scenario Expected Outcome Actual Outcome \\nEmpty Query User submits an \\nempty query. \\nSystem should display \\na warning message \\nprompting the user to \\nenter a query. \\n \\nMore Testing yet to come. \\n \\n5.7 Limitations of Testing Process \\nOne of the main limitations of the testing process was the hardware constraints, particularly the \\nabsence of high -end GPUs and distributed computing resources. The abstractive summarization \\nmodel (facebook/bart-large-cnn) is computationally intensive, and while it performed'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 59, 'page_label': '60'}, page_content='model (facebook/bart-large-cnn) is computationally intensive, and while it performed \\nwell for small and moderate loads, larger datasets and high -concurrency scenarios led to slightly \\nincreased response times. With access to more powerful hardware, such as dedicated GPUs or \\ncloud-based servers, the performance of the summarization and retrieval processes could be further \\noptimized. \\nAnother challenge involved the dataset size and completeness . While the WebMD Drug \\nReviews dataset provided a robust foundation for testing, the dataset did not cover every possible \\ndrug-related query or medical condition. This limited the scope of testing for highly specific or \\nrare queries. Future work could involve incorporating additional domain-specific datasets, such as \\nclinical trial reports or pharmaceutical databases, to improve the system’s coverage and retrieval \\naccuracy. \\n \\nAdditionally, certain real-world scenarios remained untested. For example, handling adversarial'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 59, 'page_label': '60'}, page_content='Additionally, certain real-world scenarios remained untested. For example, handling adversarial \\ninputs where users intentionally enter conflicting or misleading queries, such as “positive side \\neffects of a drug,” was tested to a limited extent. Expanding the robustness tests to cover \\nadversarial or ambiguous user inputs more comprehensively is a key area for future work.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 60, 'page_label': '61'}, page_content='In future work, these limitations will be addressed by: \\n● Leveraging cloud-based infrastructure: To support high-performance computations and \\nscalability. \\n● Expanding the dataset scope:  Incorporating more comprehensive drug and medical -\\nrelated datasets. \\n● Conducting adversarial and long -duration testing: To ensure system resilience under \\nextreme conditions. \\n● Incorporating human feedback:  To complement quantitative metrics and improve \\noverall system quality. \\n \\n \\n5.9 Chapter Summary \\nThe research presented an extensive validation approach to establish that the RAG Pipeline with \\nprompt compression fulfilled its functional parameters. Functional testing alongside non -\\nfunctional testing and model evaluation together with edge case testing  and testing process \\nlimitations defined the main outcomes and necessary enhancements for future development. \\nFunctional testing verified that primary system elements query processing, chunk retrieval, prompt'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 60, 'page_label': '61'}, page_content='Functional testing verified that primary system elements query processing, chunk retrieval, prompt \\ncompression and user interface through Streamli t operated as designed and fulfilled functional \\nspecifications. The system executed user queries to retrieve appropriate information which it \\ntransformed into usable compressed prompts that remained accurate throughout the process.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 61, 'page_label': '62'}, page_content='Chapter 6: Interim Conclusion \\n6.1 Chapter Overview \\nThe implementation and testing stages of RAG Pipeline with prompt compression received \\nevaluation in this chapter for their achievement of original project goals. The current achievements \\nprove substantial advancement in developing an expandable and depend able framework that \\nretrieves and summarizes drug-related information while maintaining user-friendliness. \\n \\n6.2 Achievements of Aims & Objectives \\nThe research objective of this project involves creating and assessing a Retrieval -Augmented \\nGeneration (RAG) pipeline that incorporates prompt compression to effectively retrieve and \\nsummarize drug-related data from extensive datasets. The system connects  FAISS and Sentence-\\nBERT retrieval models and extractive -abstractive summarization models to compact retrieved \\ninformation and retain semantic accuracy alongside contextual relevance. The main goal of this'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 61, 'page_label': '62'}, page_content='information and retain semantic accuracy alongside contextual relevance. The main goal of this \\nproject involves creating and validating a hybrid compression model which maximizes token \\nefficiency while preserving output quality. \\nThe research target has been successfully met through working implementations of the critical \\nstages starting from data preprocessing to vectorization and retrieval and hybrid compression \\ntechniques and performance evaluations. The system retrieves necessa ry information efficiently \\nbefore using extractive keyword prioritization along with abstractive BART summarization to \\ncompress the data and show token -efficient final prompts. Program effectiveness together with \\nsystem robustness emerges through testing and evaluation results from actual applications. \\n \\n6.3 Challenges and Lessons Learned \\nThe development of the RAG Pipeline with prompt compression  presented several challenges'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 61, 'page_label': '62'}, page_content=\"The development of the RAG Pipeline with prompt compression  presented several challenges \\nduring the design, implementation, and testing phases. Overcoming these challenges provided \\nvaluable insights that led to key system improvements, optimization strategies, and plans for future \\nenhancements. \\n1. Challenge: Slow Query Retrieval under Large Dataset Loads \\nWhen the dataset exceeded 500K chunks the queries took longer to respond than anticipated which \\nresulted in slower retrieval. Long or complex queries and high concurrency rates both resulted in \\nnoticeable slowness during the system's operation. \\nThe initial design relied on a simple FAISS index configuration with limited optimization. By \\nexperimenting with batching techniques, alternative retrieval distance metrics (Euclidean vs \\ncosine similarity), and partitioned indexing, the system was optimized to handle larger datasets \\nefficiently. Moving forward, integrating distributed FAISS or hierarchical clustering for faster\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 61, 'page_label': '62'}, page_content='efficiently. Moving forward, integrating distributed FAISS or hierarchical clustering for faster \\nsearches on large datasets could further improve performance.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 62, 'page_label': '63'}, page_content='2. Challenge: Over-Compression of Retrieved Content \\nThe initial summarization process, which prioritized extractive summarization before passing \\nchunks to the abstractive BART summarizer, often resulted in missing critical details due to overly \\naggressive compression. This was reflected in lower -than-expected ROUGE -L scores in some \\ncases (below 0.4 during early tests). \\nThe extractive summarization phase removed essential content when using keyword compression \\nmethods thus causing over compression . The quality of content retention improved when the \\nabstractive summarizer received a larger number of extracted sentences from the testing phase. \\nThe system successfully implemented dynamic sentence retrieval methods which used both query \\nlength and complexity for optimal performance. \\n3. Challenge: Low Retrieval Precision for Ambiguous Queries \\n Ambiguous or vague queries (e.g., \"What is this drug used for?\") led to the retrieval of irrelevant'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 62, 'page_label': '63'}, page_content=\"or partially relevant chunks. This affected Recall @ k and user satisfaction, as some queries did \\nnot provide the expected context or relevant information. \\nAmbiguous queries require better handling to improve retrieval precision. The testing process \\nrevealed that expanding queries using synonyms or related terms  (query expansion) can help \\nmatch a wider range of relevant chunks. Incorporating semantic query augmentation based on \\ncontextual embeddings proved useful in initial experiments. \\n4. Challenge: Handling Noisy and Incomplete Queries \\n The system's query encoding performance suffered while retrieving information because noisy \\ninputs with misspellings and typos or incomplete phrases were found to be detrimental. Many \\nqueries were successfully processed by the system yet particular ambigu ous or typo-laden inputs \\npresented challenges for retrieval and summarization processes. \\nPreprocessing user queries using spell-checking, token normalization, and query cleaning\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 62, 'page_label': '63'}, page_content='Preprocessing user queries using spell-checking, token normalization, and query cleaning  \\nsignificantly improved retrieval performance. Handling noisy inputs effectively involves not only \\ncorrecting errors but also interpreting user intent. \\n5. Challenge: High Latency in Abstractive Summarization \\nThe BART-based abstractive summarization model caused delays when processing large chunks \\nof retrieved content, especially for long queries with many relevant chunks. \\nAbstractive summarization can be optimized by reducing the length of input sequences through \\nmore effective extractive summarization. Additionally, summarization latency can be further \\nimproved by parallelizing summarization tasks or experimenting with faster summarization \\nmodels (e.g., PEGASUS, T5).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 63, 'page_label': '64'}, page_content='6.4 Remaining Work \\nA series of tasks along with improvements have been identified for complete system development \\nwhile preparing the system for deployment. The system development will focus on development \\nmilestones and planned testing phases together with improvements to r etrieval and compression \\nalgorithms and user interface (UI). The identified tasks will boost system scalability as well as \\nimprove performance and user experience. \\nDevelopment Milestones \\n1. Integrate Advanced Query Expansion Techniques \\nImplement semantic query expansion using synonym detection and contextual embeddings to \\nimprove retrieval precision. \\n2. Fine-Tune the Hybrid Compression Model \\nThe BART summarization model requires a specific domain dataset refinement such as clinical \\ntrials or drug reports for better accuracy results. \\n3. Enhance Retrieval Mechanism with Cosine Similarity \\nThe current FAISS index method of Euclidean distance retrieval needs replacement or'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 63, 'page_label': '64'}, page_content='The current FAISS index method of Euclidean distance retrieval needs replacement or \\nenhancement with cosine similarity for better chunk relevance. \\n4. Optimize System Performance for High-Concurrency Loads \\nIntroduce caching for frequently queried embeddings and retrieval results to minimize latency \\nduring concurrent user queries.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 64, 'page_label': '65'}, page_content=\"Planned Testing Phases \\n1. Adversarial Testing \\nSubmit queries with contradictory or confusing terms to test the system’s ability to handle \\nambiguity. \\n2. Prolonged Stress Testing \\nSimulate continuous user queries over 12 -24 hours to test for memory leaks or performance \\ndegradation. \\n3. Extended Usability Testing \\nConduct sessions where users test the system, providing feedback on the UI and overall \\nexperience. \\n4. Edge Case Testing with Large Data \\nEvaluate the performance and response times when the dataset size is doubled or tripled. \\n \\n \\n \\n6.5 Chapter Summary \\nThe research project's testing process along with its investigation results have been thoroughly \\nexplored in this chapter. This section outlines the testing objectives together with the criteria and \\nfinal results for the main research component and the functional and non-functional requirements \\nof the prototype. The author encountered various restrictions during the testing phase. A\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 64, 'page_label': '65'}, page_content='of the prototype. The author encountered various restrictions during the testing phase. A \\ncomprehensive discussion regarding the testing challenges encountered by the author has been \\nincluded.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", task_type=\"retrieval_document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(768)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./docsChenula IPD.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs\\\\Chenula IPD.pdf', 'total_pages': 65, 'page': 0, 'page_label': '1'}, page_content='INFORMATICS INSTITUTE OF TECHNOLOGY \\nIn Collaboration with \\nUNIVERSITY OF WESTMINSTER \\n \\nHybrid Prompt Compression for RAG Pipelines \\n \\nA Project Proposal by \\nChenula Senkith Jayasinghe \\n \\nSupervised by \\nMr Vinula Uthsara Buthgamumudalige \\n \\n \\n \\n \\n \\n \\n02/2025')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = './docs'\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        # print(\"Processing file:\", file, end=\"...\\n\")\n",
    "        all_split_texts = []\n",
    "        loader = PyPDFLoader(os.path.join(dir, file))\n",
    "        print(dir + file)\n",
    "        docs = loader.load()\n",
    "        split_texts = text_splitter.split_documents(docs)\n",
    "        all_split_texts.extend(split_texts)\n",
    "        # print(all_split_texts)\n",
    "        # print(split_texts)\n",
    "\n",
    "        uuids = [str(uuid4()) for _ in range(len(all_split_texts))]\n",
    "        # print(uuids)\n",
    "        vector_store.add_documents(documents=all_split_texts, ids=uuids)\n",
    "        # print(\"done\")\n",
    "all_split_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['089309db-509f-4c97-a8a5-ff435698df1a',\n",
       " 'a68d1def-f487-4b59-8a42-bbf648389b9c',\n",
       " '85b4d364-4dfe-40b6-a248-00f5c7dedd64',\n",
       " '0ca3f3f7-8aec-4011-ba3a-5d59db9563c6',\n",
       " 'b4baefc2-d0ed-4ef6-b2ee-cd1e11a7645c',\n",
       " '3b6d6e46-f60d-4952-8aa2-a659305bdf54',\n",
       " '4a89abf6-6138-4f05-9133-978b57be248f',\n",
       " 'a6f08c0a-8bb8-4f1f-b45c-855287bf5107',\n",
       " '45f64788-4cd4-44bc-98b0-cf03b05b0e04',\n",
       " 'f5d3bdbb-0c7d-4728-a9eb-0263071904c1',\n",
       " 'cf95a61d-3c4f-4917-a20e-cdbbf66f5cc0',\n",
       " '8ef0f3e4-c35a-4cf0-966d-467ab1ce6618',\n",
       " 'ccedea6c-45f6-4239-8566-f11ca77fff55',\n",
       " '8e916611-8929-4e66-9e62-9a0da2d2bc45',\n",
       " '987636a8-5922-44dc-82d2-2a04353a42a7',\n",
       " '0497fe2b-c9a3-4395-b661-03ab0e8949d3',\n",
       " '0fda5af4-141d-43f8-b1ce-a4104f69c8bc',\n",
       " 'c8d81bf5-96c2-4a08-9e1b-fb6cc63aecb3',\n",
       " '89de2833-33b8-4eb9-9f05-aaee02a3834a',\n",
       " '001649a5-610c-4673-aaf5-60827e94f0c5',\n",
       " 'c1ef8e58-235e-4df2-bb4c-5da3c2ac1230',\n",
       " 'c285d8cd-4cda-428e-ad26-68f13191dfec',\n",
       " '35bad6f0-bfc0-4994-9c97-5df0fdd4ff90',\n",
       " 'a2fcbb20-81e4-4f0d-a465-387b18a5f3b6',\n",
       " '5b5e800d-5852-4434-af8b-2bd0f2b23479',\n",
       " 'f1421805-19de-4cd7-9118-bf7f6538c577',\n",
       " '5f91660c-066f-48b9-b8a7-9c182c19c6a5',\n",
       " '78a578aa-ff99-4bef-96b0-32b65c49417f',\n",
       " '11db3725-434a-4190-a229-65ee0f3b112a',\n",
       " '9fd6002d-6e40-4c3e-81f4-46cd22d262a9',\n",
       " '81258fba-ed52-4a3b-8bdd-327f88d2e783',\n",
       " 'f8002d8d-0d01-4025-b609-f00d81b5aff4',\n",
       " '00f5b345-13b9-4c1f-b119-a5e0fbb363a6',\n",
       " '4b1a9f87-b178-40cd-b742-ca9a4e27a274',\n",
       " '6190217d-f94b-4a1f-8610-5c5d63190a3e',\n",
       " '881ab899-329a-4dea-bb2d-261e27993d79',\n",
       " '12cf562a-865e-41dd-b840-b572ad08087f',\n",
       " 'eda5c605-8f4a-40ee-8a51-fab77b3440a1',\n",
       " 'f8b63501-de3a-4944-adc5-2d9ac0319161',\n",
       " '647eec02-b34e-4db3-85d6-f548ec4a8479',\n",
       " 'e3ba9474-bdd6-4b32-900b-068635f04811',\n",
       " 'dd777d09-5f4b-4780-aeee-df430f19b6b5',\n",
       " '466c38a3-9f28-412b-85c1-603738098349',\n",
       " 'c8d3300a-422d-4c10-bc18-bfee31e6ea95',\n",
       " 'c5a3942c-28d7-4615-bd7a-510728814749',\n",
       " 'a1ab62f5-df12-40a1-86f5-8d15a5edd002',\n",
       " '2471b48b-ca99-4c5f-a373-7d9e25c5fbff',\n",
       " '2fb75ca7-6acd-48e5-a38b-606dc77b8f35',\n",
       " '4ca1aaf2-a24a-468f-af6a-e355f93d1dc2',\n",
       " '8050af27-2160-4635-92ac-68476cfa28b6',\n",
       " '085487b9-51fc-4fe5-b759-9fed740166e8',\n",
       " '4ff58bf8-3685-46d0-acf6-5310e9abfad7',\n",
       " '57e16f60-dfbf-4174-ac54-584c150a58d7',\n",
       " '588ddb8f-51dc-4f31-83cb-0b2d87403c0d',\n",
       " '0b8973ee-f414-41a3-86ba-82258ffbec57',\n",
       " '9f83f395-3588-46f6-9175-0dee47b04868',\n",
       " '8934185b-caf2-46f9-9b8e-49e0d24212cc',\n",
       " '3d833199-b8d1-4459-bb03-016db0f7f19a',\n",
       " '8d5d11c5-8fe3-417e-9e76-417b1b26f43e',\n",
       " '707ad303-6cc4-47d7-8c4b-266132b03ac2',\n",
       " '5a84d14a-8cc7-4a23-bf1e-ef4db0bd8175',\n",
       " 'fbf29e48-3e4e-42cf-91ca-27fa67bc887b',\n",
       " '8beb11a5-2b4c-47f9-81e9-4725be43eda2',\n",
       " 'fe499f0e-a90c-43d7-899c-594c1c4afeea',\n",
       " '9fa32472-cc68-4b2a-89ee-7e94a1ca06ea',\n",
       " 'e72c6c3c-50b3-4050-b4ee-c06deedc4d1e',\n",
       " 'f6526ed2-9d2c-4a72-b20f-d41cc2efa2ea',\n",
       " '4e9ab5a4-3503-4fa9-bfdf-ad385beb291e',\n",
       " '20f955ef-dc2e-4728-b4ab-709bd17774f7',\n",
       " '04295b92-13a6-48c9-9e17-92903a99de9d',\n",
       " 'd0b80191-dd28-429c-8514-7ce3defc907a',\n",
       " '9efdf99b-927a-4fb1-a865-62f842e3d6c1',\n",
       " 'c1357e94-9308-492d-aa62-dbaf371610e4',\n",
       " 'ece407db-23cb-4265-a0e5-93ee99b86fe7',\n",
       " 'ab589fb0-1ae2-4344-bf60-794c756e6ae2',\n",
       " '8e2cf140-d533-4f88-8e70-9212827b396e',\n",
       " '242246f9-900a-4e46-9bf1-665b366448f7',\n",
       " '57e22c4c-1cf4-4314-b7f1-b0cdbb55c1cd',\n",
       " '195dd77e-5482-4c63-afe7-58981fdbff11',\n",
       " 'e730c4b8-8731-496c-81ca-422fe3ddd684',\n",
       " 'ad1a7a82-17a2-4151-8cf5-bf72b7239a3e',\n",
       " 'bb748eee-51ca-47d4-adeb-eaabfa5f3cb0',\n",
       " '9c86e128-0bee-4b3e-a17e-86ded584017c',\n",
       " '08da43af-caed-4e37-83a3-78e4d989ca8f',\n",
       " '73a7d6c4-77f2-4c0c-8223-a48e9f0febeb',\n",
       " '411c70fb-843b-4464-b830-dbd3d0aa3ade',\n",
       " 'f54be0a7-d025-45da-a492-736c829bf7d8',\n",
       " 'aa480431-09de-4de2-ae2a-95f3bcf281be',\n",
       " '96dd6339-fd72-4e70-9fce-3e3381f4d84d',\n",
       " 'cdbf6e9f-9464-47d7-b98e-dae31538e6c7',\n",
       " '6de373e5-c3ed-4041-afe5-3396328e9ad9',\n",
       " '852d67c2-2cef-4377-a2d8-4591bb3194dd',\n",
       " '2c208f92-bc2f-499a-aa83-644069df1b6a',\n",
       " '5a27cfe4-be66-4cfa-abfe-087c19fbc6ea',\n",
       " '0b7b8afe-0578-4185-9462-7f4b49e68d42',\n",
       " '3602dad1-ab24-4799-91c3-d5ff6c934eed',\n",
       " '7a85e180-98c8-4285-9c33-be28df1ea064',\n",
       " 'ff9ab2fd-20df-4e67-b7ca-9e8dffd65eca',\n",
       " '460ea1f7-dcca-4670-905f-362f4105cc94',\n",
       " 'd864acb2-806a-49e7-9ac9-c5c362737984',\n",
       " '5f759ae7-823b-4808-842a-d55d12a851e6',\n",
       " '8a12ada6-16f5-4d93-bbd7-85ac22411e9c',\n",
       " '1bc08653-fad6-4344-93a6-761c5e943ba4',\n",
       " '4215d32e-9941-4fdf-bc68-dcf72204c4e2',\n",
       " '5d27fa3b-8042-4e65-80bc-348a08717fad',\n",
       " '85f0f1ef-841a-4c82-9e5b-9ed40bbe927d',\n",
       " 'a71e0b33-2070-49e3-8f0c-94d001a9babd',\n",
       " '846b7e28-6028-4b2a-96de-f4c119c48971',\n",
       " '9656db68-ab73-489e-83c2-a581d9eed66c',\n",
       " 'de927851-8f97-487a-a055-fdd86675e008',\n",
       " '19d5cd14-2803-4d5f-bf56-23692d65c4af',\n",
       " 'f16004dc-fd2c-44ca-8a24-a63b9b30e788',\n",
       " '9cd64fdc-db5b-493c-bab7-b077f823b206',\n",
       " '19c72358-bfe2-4b50-93cf-cc8aef3a0386',\n",
       " '0887efb0-b028-46df-9a2d-67b10e789279',\n",
       " 'a5aedbdb-4a76-4782-a1b2-3cd36a59b3a5',\n",
       " '31121ea5-f391-485f-87e8-6dac3719a34d',\n",
       " 'eb31ec09-8528-4707-b40b-a6e336c2da94',\n",
       " '60482692-043e-4062-a338-07851e209643',\n",
       " 'e0146ac9-1587-4a51-a71a-8003c18f4d3a',\n",
       " '524c5c97-859d-4b73-b950-408f267f08b8',\n",
       " '859411e9-b522-46f2-be11-4ac901660e05',\n",
       " '5384700d-457a-4136-9810-e92d2336c421',\n",
       " 'ff5b8537-cba1-43c4-a1b7-5659dfcd8d18',\n",
       " 'dc16bbee-4865-4da4-b32b-a18b47d3fb5d',\n",
       " '6bf18a63-96b4-4047-ad2f-e533dd4e719a',\n",
       " '2faa03f3-d979-4a9d-b2c2-8c90ab819ff1',\n",
       " '54ee84ce-9b2e-4dd4-8ddb-5ec8db7b695f',\n",
       " 'f205e5cd-4098-496f-91e3-ced48fa2ea56',\n",
       " '5237ea64-60ca-4f2c-b701-f0766f6a3a4b',\n",
       " 'b6177c16-69ac-4f81-9aaa-ca9158833efc',\n",
       " 'e6cafe1a-0875-4896-bac0-26ef4d012811']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(all_splits))]\n",
    "uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 0, 'page_label': '1'}, page_content='INFORMATICS INSTITUTE OF TECHNOLOGY \\nIn Collaboration with \\nUNIVERSITY OF WESTMINSTER \\n \\nHybrid Prompt Compression for RAG Pipelines \\n \\nA Project Proposal by \\nChenula Senkith Jayasinghe \\n \\nSupervised by \\nMr Vinula Uthsara Buthgamumudalige \\n \\n \\n \\n \\n \\n \\n02/2025')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs\\\\Chenula IPD.pdf', 'total_pages': 65, 'page': 0, 'page_label': '1'}, page_content='INFORMATICS INSTITUTE OF TECHNOLOGY \\nIn Collaboration with \\nUNIVERSITY OF WESTMINSTER \\n \\nHybrid Prompt Compression for RAG Pipelines \\n \\nA Project Proposal by \\nChenula Senkith Jayasinghe \\n \\nSupervised by \\nMr Vinula Uthsara Buthgamumudalige \\n \\n \\n \\n \\n \\n \\n02/2025')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_split_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 0, 'page_label': '1'}, page_content='INFORMATICS INSTITUTE OF TECHNOLOGY \\nIn Collaboration with \\nUNIVERSITY OF WESTMINSTER \\n \\nHybrid Prompt Compression for RAG Pipelines \\n \\nA Project Proposal by \\nChenula Senkith Jayasinghe \\n \\nSupervised by \\nMr Vinula Uthsara Buthgamumudalige \\n \\n \\n \\n \\n \\n \\n02/2025')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['089309db-509f-4c97-a8a5-ff435698df1a',\n",
       " 'a68d1def-f487-4b59-8a42-bbf648389b9c',\n",
       " '85b4d364-4dfe-40b6-a248-00f5c7dedd64',\n",
       " '0ca3f3f7-8aec-4011-ba3a-5d59db9563c6',\n",
       " 'b4baefc2-d0ed-4ef6-b2ee-cd1e11a7645c',\n",
       " '3b6d6e46-f60d-4952-8aa2-a659305bdf54',\n",
       " '4a89abf6-6138-4f05-9133-978b57be248f',\n",
       " 'a6f08c0a-8bb8-4f1f-b45c-855287bf5107',\n",
       " '45f64788-4cd4-44bc-98b0-cf03b05b0e04',\n",
       " 'f5d3bdbb-0c7d-4728-a9eb-0263071904c1',\n",
       " 'cf95a61d-3c4f-4917-a20e-cdbbf66f5cc0',\n",
       " '8ef0f3e4-c35a-4cf0-966d-467ab1ce6618',\n",
       " 'ccedea6c-45f6-4239-8566-f11ca77fff55',\n",
       " '8e916611-8929-4e66-9e62-9a0da2d2bc45',\n",
       " '987636a8-5922-44dc-82d2-2a04353a42a7',\n",
       " '0497fe2b-c9a3-4395-b661-03ab0e8949d3',\n",
       " '0fda5af4-141d-43f8-b1ce-a4104f69c8bc',\n",
       " 'c8d81bf5-96c2-4a08-9e1b-fb6cc63aecb3',\n",
       " '89de2833-33b8-4eb9-9f05-aaee02a3834a',\n",
       " '001649a5-610c-4673-aaf5-60827e94f0c5',\n",
       " 'c1ef8e58-235e-4df2-bb4c-5da3c2ac1230',\n",
       " 'c285d8cd-4cda-428e-ad26-68f13191dfec',\n",
       " '35bad6f0-bfc0-4994-9c97-5df0fdd4ff90',\n",
       " 'a2fcbb20-81e4-4f0d-a465-387b18a5f3b6',\n",
       " '5b5e800d-5852-4434-af8b-2bd0f2b23479',\n",
       " 'f1421805-19de-4cd7-9118-bf7f6538c577',\n",
       " '5f91660c-066f-48b9-b8a7-9c182c19c6a5',\n",
       " '78a578aa-ff99-4bef-96b0-32b65c49417f',\n",
       " '11db3725-434a-4190-a229-65ee0f3b112a',\n",
       " '9fd6002d-6e40-4c3e-81f4-46cd22d262a9',\n",
       " '81258fba-ed52-4a3b-8bdd-327f88d2e783',\n",
       " 'f8002d8d-0d01-4025-b609-f00d81b5aff4',\n",
       " '00f5b345-13b9-4c1f-b119-a5e0fbb363a6',\n",
       " '4b1a9f87-b178-40cd-b742-ca9a4e27a274',\n",
       " '6190217d-f94b-4a1f-8610-5c5d63190a3e',\n",
       " '881ab899-329a-4dea-bb2d-261e27993d79',\n",
       " '12cf562a-865e-41dd-b840-b572ad08087f',\n",
       " 'eda5c605-8f4a-40ee-8a51-fab77b3440a1',\n",
       " 'f8b63501-de3a-4944-adc5-2d9ac0319161',\n",
       " '647eec02-b34e-4db3-85d6-f548ec4a8479',\n",
       " 'e3ba9474-bdd6-4b32-900b-068635f04811',\n",
       " 'dd777d09-5f4b-4780-aeee-df430f19b6b5',\n",
       " '466c38a3-9f28-412b-85c1-603738098349',\n",
       " 'c8d3300a-422d-4c10-bc18-bfee31e6ea95',\n",
       " 'c5a3942c-28d7-4615-bd7a-510728814749',\n",
       " 'a1ab62f5-df12-40a1-86f5-8d15a5edd002',\n",
       " '2471b48b-ca99-4c5f-a373-7d9e25c5fbff',\n",
       " '2fb75ca7-6acd-48e5-a38b-606dc77b8f35',\n",
       " '4ca1aaf2-a24a-468f-af6a-e355f93d1dc2',\n",
       " '8050af27-2160-4635-92ac-68476cfa28b6',\n",
       " '085487b9-51fc-4fe5-b759-9fed740166e8',\n",
       " '4ff58bf8-3685-46d0-acf6-5310e9abfad7',\n",
       " '57e16f60-dfbf-4174-ac54-584c150a58d7',\n",
       " '588ddb8f-51dc-4f31-83cb-0b2d87403c0d',\n",
       " '0b8973ee-f414-41a3-86ba-82258ffbec57',\n",
       " '9f83f395-3588-46f6-9175-0dee47b04868',\n",
       " '8934185b-caf2-46f9-9b8e-49e0d24212cc',\n",
       " '3d833199-b8d1-4459-bb03-016db0f7f19a',\n",
       " '8d5d11c5-8fe3-417e-9e76-417b1b26f43e',\n",
       " '707ad303-6cc4-47d7-8c4b-266132b03ac2',\n",
       " '5a84d14a-8cc7-4a23-bf1e-ef4db0bd8175',\n",
       " 'fbf29e48-3e4e-42cf-91ca-27fa67bc887b',\n",
       " '8beb11a5-2b4c-47f9-81e9-4725be43eda2',\n",
       " 'fe499f0e-a90c-43d7-899c-594c1c4afeea',\n",
       " '9fa32472-cc68-4b2a-89ee-7e94a1ca06ea',\n",
       " 'e72c6c3c-50b3-4050-b4ee-c06deedc4d1e',\n",
       " 'f6526ed2-9d2c-4a72-b20f-d41cc2efa2ea',\n",
       " '4e9ab5a4-3503-4fa9-bfdf-ad385beb291e',\n",
       " '20f955ef-dc2e-4728-b4ab-709bd17774f7',\n",
       " '04295b92-13a6-48c9-9e17-92903a99de9d',\n",
       " 'd0b80191-dd28-429c-8514-7ce3defc907a',\n",
       " '9efdf99b-927a-4fb1-a865-62f842e3d6c1',\n",
       " 'c1357e94-9308-492d-aa62-dbaf371610e4',\n",
       " 'ece407db-23cb-4265-a0e5-93ee99b86fe7',\n",
       " 'ab589fb0-1ae2-4344-bf60-794c756e6ae2',\n",
       " '8e2cf140-d533-4f88-8e70-9212827b396e',\n",
       " '242246f9-900a-4e46-9bf1-665b366448f7',\n",
       " '57e22c4c-1cf4-4314-b7f1-b0cdbb55c1cd',\n",
       " '195dd77e-5482-4c63-afe7-58981fdbff11',\n",
       " 'e730c4b8-8731-496c-81ca-422fe3ddd684',\n",
       " 'ad1a7a82-17a2-4151-8cf5-bf72b7239a3e',\n",
       " 'bb748eee-51ca-47d4-adeb-eaabfa5f3cb0',\n",
       " '9c86e128-0bee-4b3e-a17e-86ded584017c',\n",
       " '08da43af-caed-4e37-83a3-78e4d989ca8f',\n",
       " '73a7d6c4-77f2-4c0c-8223-a48e9f0febeb',\n",
       " '411c70fb-843b-4464-b830-dbd3d0aa3ade',\n",
       " 'f54be0a7-d025-45da-a492-736c829bf7d8',\n",
       " 'aa480431-09de-4de2-ae2a-95f3bcf281be',\n",
       " '96dd6339-fd72-4e70-9fce-3e3381f4d84d',\n",
       " 'cdbf6e9f-9464-47d7-b98e-dae31538e6c7',\n",
       " '6de373e5-c3ed-4041-afe5-3396328e9ad9',\n",
       " '852d67c2-2cef-4377-a2d8-4591bb3194dd',\n",
       " '2c208f92-bc2f-499a-aa83-644069df1b6a',\n",
       " '5a27cfe4-be66-4cfa-abfe-087c19fbc6ea',\n",
       " '0b7b8afe-0578-4185-9462-7f4b49e68d42',\n",
       " '3602dad1-ab24-4799-91c3-d5ff6c934eed',\n",
       " '7a85e180-98c8-4285-9c33-be28df1ea064',\n",
       " 'ff9ab2fd-20df-4e67-b7ca-9e8dffd65eca',\n",
       " '460ea1f7-dcca-4670-905f-362f4105cc94',\n",
       " 'd864acb2-806a-49e7-9ac9-c5c362737984',\n",
       " '5f759ae7-823b-4808-842a-d55d12a851e6',\n",
       " '8a12ada6-16f5-4d93-bbd7-85ac22411e9c',\n",
       " '1bc08653-fad6-4344-93a6-761c5e943ba4',\n",
       " '4215d32e-9941-4fdf-bc68-dcf72204c4e2',\n",
       " '5d27fa3b-8042-4e65-80bc-348a08717fad',\n",
       " '85f0f1ef-841a-4c82-9e5b-9ed40bbe927d',\n",
       " 'a71e0b33-2070-49e3-8f0c-94d001a9babd',\n",
       " '846b7e28-6028-4b2a-96de-f4c119c48971',\n",
       " '9656db68-ab73-489e-83c2-a581d9eed66c',\n",
       " 'de927851-8f97-487a-a055-fdd86675e008',\n",
       " '19d5cd14-2803-4d5f-bf56-23692d65c4af',\n",
       " 'f16004dc-fd2c-44ca-8a24-a63b9b30e788',\n",
       " '9cd64fdc-db5b-493c-bab7-b077f823b206',\n",
       " '19c72358-bfe2-4b50-93cf-cc8aef3a0386',\n",
       " '0887efb0-b028-46df-9a2d-67b10e789279',\n",
       " 'a5aedbdb-4a76-4782-a1b2-3cd36a59b3a5',\n",
       " '31121ea5-f391-485f-87e8-6dac3719a34d',\n",
       " 'eb31ec09-8528-4707-b40b-a6e336c2da94',\n",
       " '60482692-043e-4062-a338-07851e209643',\n",
       " 'e0146ac9-1587-4a51-a71a-8003c18f4d3a',\n",
       " '524c5c97-859d-4b73-b950-408f267f08b8',\n",
       " '859411e9-b522-46f2-be11-4ac901660e05',\n",
       " '5384700d-457a-4136-9810-e92d2336c421',\n",
       " 'ff5b8537-cba1-43c4-a1b7-5659dfcd8d18',\n",
       " 'dc16bbee-4865-4da4-b32b-a18b47d3fb5d',\n",
       " '6bf18a63-96b4-4047-ad2f-e533dd4e719a',\n",
       " '2faa03f3-d979-4a9d-b2c2-8c90ab819ff1',\n",
       " '54ee84ce-9b2e-4dd4-8ddb-5ec8db7b695f',\n",
       " 'f205e5cd-4098-496f-91e3-ced48fa2ea56',\n",
       " '5237ea64-60ca-4f2c-b701-f0766f6a3a4b',\n",
       " 'b6177c16-69ac-4f81-9aaa-ca9158833efc',\n",
       " 'e6cafe1a-0875-4896-bac0-26ef4d012811']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector_store.add_documents(documents=all_splits, ids=uuids)\n",
    "\n",
    "# # Ensure that all_splits and uuids are not None and have the same length\n",
    "# if all_splits is not None and uuids is not None and len(all_splits) == len(uuids):\n",
    "#     try:\n",
    "#         vector_store.add_documents(documents=all_splits, ids=uuids)\n",
    "#     except AssertionError as e:\n",
    "#         # Print the dimensions of the embeddings and the expected dimension\n",
    "#         embeddings_np = vector_store._embed_documents([doc.page_content for doc in all_splits])\n",
    "#         embeddings_np = np.array(embeddings_np)  # Convert to NumPy array\n",
    "#         print(f\"Embedding dimension: {embeddings_np.shape[1]}\")\n",
    "#         print(f\"Expected dimension: {vector_store.d}\")\n",
    "#         raise e\n",
    "# else:\n",
    "#     raise ValueError(\"Documents and IDs must be non-None and have the same length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2. Embedding Generation \\n \\n \\n \\n \\n \\n3. FAISS Index Initialization \\n \\n \\n \\n \\n4. Query Vectorization and Retrieval'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"Tell me about query retreival\",\n",
    "    # k=8,\n",
    ")\n",
    "print(len(results))\n",
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain_community\n",
    "\n",
    "# Local vector store via Chroma\n",
    "%pip install -qU langchain_chroma\n",
    "\n",
    "# Local inference and embeddings via Ollama\n",
    "%pip install -qU langchain_ollama\n",
    "\n",
    "# Web Loader\n",
    "%pip install -qU beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n\\n\\n\\nNlp\\nLanguage-Model\\nAgent\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nAdversarial Attacks on LLMs\\n\\n\\n »\\n\\nPrompt Engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2024 Lil\\'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "data\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "# all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fca60273-b5ca-4ced-bb22-3b27d10e991c', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 48, 'page_label': '49'}, page_content='Figure 8 User Interface'),\n",
       " Document(id='690f6e21-e312-437e-b787-24231af46af5', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 47, 'page_label': '48'}, page_content='User Interface \\n \\n \\n \\n>> Next Page'),\n",
       " Document(id='8758dbc2-7ae7-4bd7-9da8-2fe8f2b47d14', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 44, 'page_label': '45'}, page_content='2. Embedding Generation \\n \\n \\n \\n \\n \\n3. FAISS Index Initialization \\n \\n \\n \\n \\n4. Query Vectorization and Retrieval'),\n",
       " Document(id='0b19d68a-08b2-4413-a126-8c2b54ec027b', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-02-14T00:05:05+05:30', 'author': 'User', 'moddate': '2025-02-14T00:05:05+05:30', 'source': './docs/Chenula IPD.pdf', 'total_pages': 65, 'page': 45, 'page_label': '46'}, page_content='5. Summarization and Final Prompt \\n \\n \\n \\n \\n \\n4.4 User Interface Implementation \\n4.4.1 Frontend Development')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vector_store = FAISS.load_local(\n",
    "    \"vector_store\", embeddings, allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "docs = new_vector_store.similarity_search(\"qux\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
